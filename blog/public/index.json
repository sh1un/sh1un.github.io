[{"content":"大家好，我是 Shiun，今天想和大家分享我在 eCloudValley MSP 部門擔任雲端工程師實習生的經歷。這段實習讓我學到了很多實用的雲端技術，同時也在工作中遇到了許多有趣的挑戰。 實習工作內容 在 eCloudValley 的實習期間，我主要負責以下幾項工作：\n學習使用公有雲，包括 AWS 和 Azure。 開發公司內部的 GenAI 應用。 與同期且同部門實習生共同開發專案。 定期與 Mentor 開會。 參與最終展演。 撰寫系統文件。 實習期間大事紀 專案大改方向 在 eCloudValley 實習期間，我們的專案經歷了一次重大轉變。起初，我們的任務是開發一個 AI Bot 開單助理，目的是幫助客戶在雲端遇到問題時能夠迅速獲得支援。這個專案的初步構想是：\n客戶向 AI 助理求助，並向 AI 助理提供必要資訊，例如： EC2 SG Inbound Rule, 健康檢查狀態\u0026hellip; 等等 如果客戶提供的資訊不夠明確，AI 助理要明確地告知客戶還需提供哪些資訊。 AI 助理彙總客戶問題，轉化為技術人員易於理解的語言。 將資訊轉化後，開 ticket 到開單系統。 然而，在實作過程中，我們發現這個 AI 助理的效果不如預期，且後續優化存在技術瓶頸。客戶問題過於多樣化、且問題幾乎都很具情境，不是那種有標準解答或是標準 SOP 就能解決的問題，所以 AI 助理難以處理，導致準確率低，最終還是需要人工介入，反而增加了工作量。\n因此，我們在 4 月底決定將專案轉變為一個「會議錄影機器人」。這個機器人會被邀請到 LINE 群組中，默默記錄每一條訊息以及圖片 (圖片透過 Claude 3 Sonnet 取得 Caption)。TAM 只需在群組中輸入特殊指令或貼圖即可控制錄影，最終在前端頁面查看記錄並由 LLM 總結，創建 Ticket 到 MSP 部門的 Ticket System。\n獲得 Best Tech Team 專案在 4月底、5月初大改方向，而我們必須在 5 月底展演。儘管時程緊湊，但團隊合作逐漸流暢，我們在短短不到一個月內完成了應用開發。團隊的 PO (Product Owner) 帶領我們不斷練習簡報，最終在 5/31 的展演中獲得了 Best Tech Team 的獎項，這讓我們非常開心。 實習中的專業學習心得 學會使用 AWS 及 Azure 在公有雲市場中，AWS 和 Azure 占據了領先地位。在 eCloudValley，我們通過內部的知識管理系統 (eCloudTure) 學習如何使用這些平台來部署和架設服務。這個平台讓我們可以依照課程實作 Lab，不僅學會了理論知識，還學會了動手操作。\n學習使用 GenAI 技術 在實習期間，我們需要開發一個 GenAI 應用，幫助 TAM 自動總結客戶問題並開工單給工程師解決。我學會了使用 LangChain 框架和 Azure OpenAI, Prompt Flow，但最終選擇了 AWS Bedrock 的 Claude 3 Sonnet 作為模型。學習這些技術讓我在 GenAI Hackathon 中得到了實踐機會，也讓我在使用 AI 工具時更加得心應手。\n加強了英文口說和閱讀 由於 eCloudValley 跨足多國，內部必須使用英文交流。我們每天都要進行英文開會 (Daily Scrum)，並在最終展演時使用全英文簡報。這段經歷強迫我提升英文口說能力，讓我在短短三個月內英文口說更為流暢。\n關於我喜歡 eCloudValley 的點 文化及地理面 年輕的氛圍：MSP 部門氣氛歡樂，而且主管們都很照顧。 DevOps 主管 Timmy 重視員工想法：會依照我們的專長和想要發展的領域來安排任務，非常重視員工想法。 優秀的 Mentor：特別是 KKueen！真的很有耐心。 豐富的社團活動：公司有各種社團，咖啡社特別有趣。 便利的地理位置：公司離捷運站超近，從三和國中站出來就是公司，超級方便。 遇到這麼棒的 Mentor 真的很有福氣\n食物面 喝不完的飲品：咖啡、牛奶和豆漿應有盡有。 免費午餐：中午提供免費午餐，偶爾還有西瓜，超級爽，我都吃超多西瓜。 冰棒和零食：各種零食和冰棒供應，隨時可以享用。 啤酒和調酒：雖然很少喝，但在專案尾聲放鬆一下非常不錯。 學習面 雲端平台練習：公司提供 AWS 和 Azure 帳號，讓實習生可以練習雲端技術和進行 PoC。 公司教育系統 - eCloudTure：提供 Lab 環境和完整的教材，讓我們充分練習 AWS 和 Azure。 技術講座：作為 AWS Partner，公司不定期會有原廠技術講座，對於雲端技術愛好者來說非常棒。 實習之反省與檢討 英文的重要性 在這段實習中，我深刻體會到英文的重要性。無論是學習資源還是日常工作，英文都是不可或缺的工具。掌握好英文，才能在軟體開發這條路上如魚得水。\n紀錄自己的成長 實習期間，我們的 Mentor 要求我們寫日誌，紀錄每天的學習。這讓我意識到筆記不僅是為了複習，更是為了意識到自己的成長。通過不斷的紀錄和反思，我感受到成就感，進一步提升了學習動力。\n已經養成一個習慣了 XD，直至今日每天都在寫\n結語 在 eCloudValley 的實習經歷，是我職涯中的一個重要里程碑。不僅提升了技術能力，也讓我在團隊合作和問題解決上得到了寶貴的經驗。這段實習讓我更具信心，迎接未來的挑戰。\n希望我的分享對大家有所幫助，也希望有更多的機會能和大家交流技術心得。感謝大家的閱讀！\n","permalink":"https://shiun.me/blog/2024-ecloudvalley-internship/","summary":"大家好，我是 Shiun，今天想和大家分享我在 eCloudValley MSP 部門擔任雲端工程師實習生的經歷。這段實習讓我學到了很多實用的雲端技術，同時也在工作中遇到了許多有趣的挑戰。 實習工作內容 在 eCloudValley 的實習期間，我主要負責以下幾項工作：\n學習使用公有雲，包括 AWS 和 Azure。 開發公司內部的 GenAI 應用。 與同期且同部門實習生共同開發專案。 定期與 Mentor 開會。 參與最終展演。 撰寫系統文件。 實習期間大事紀 專案大改方向 在 eCloudValley 實習期間，我們的專案經歷了一次重大轉變。起初，我們的任務是開發一個 AI Bot 開單助理，目的是幫助客戶在雲端遇到問題時能夠迅速獲得支援。這個專案的初步構想是：\n客戶向 AI 助理求助，並向 AI 助理提供必要資訊，例如： EC2 SG Inbound Rule, 健康檢查狀態\u0026hellip; 等等 如果客戶提供的資訊不夠明確，AI 助理要明確地告知客戶還需提供哪些資訊。 AI 助理彙總客戶問題，轉化為技術人員易於理解的語言。 將資訊轉化後，開 ticket 到開單系統。 然而，在實作過程中，我們發現這個 AI 助理的效果不如預期，且後續優化存在技術瓶頸。客戶問題過於多樣化、且問題幾乎都很具情境，不是那種有標準解答或是標準 SOP 就能解決的問題，所以 AI 助理難以處理，導致準確率低，最終還是需要人工介入，反而增加了工作量。\n因此，我們在 4 月底決定將專案轉變為一個「會議錄影機器人」。這個機器人會被邀請到 LINE 群組中，默默記錄每一條訊息以及圖片 (圖片透過 Claude 3 Sonnet 取得 Caption)。TAM 只需在群組中輸入特殊指令或貼圖即可控制錄影，最終在前端頁面查看記錄並由 LLM 總結，創建 Ticket 到 MSP 部門的 Ticket System。","title":"2024 伊雲谷實習計畫 - 雲端工程師實習心得"},{"content":"情境描述 上圖顯示的是我剛在 Cognito User Pool 中新增了一個 user，可以注意到箭頭處顯示 Force change password。\n當這個 user 嘗試首次登入時，他們會遇到這樣的情況:\n{ \u0026#34;message\u0026#34;: \u0026#34;New password required\u0026#34;， \u0026#34;challengeName\u0026#34;: \u0026#34;NEW_PASSWORD_REQUIRED\u0026#34;， \u0026#34;session\u0026#34;: \u0026#34;AYABeAsYJsR3yEr0iJssKPPUPEgAHQABAAdTZXJ2aWNlABBDb2duaXRvVXNlclBvb2xzAAEAB2F3cy1rbXMAS2Fybjphd3M6a21zOnVzLXdlc3QtMjowMTU3MzY3MjcxOTg6a2V5LzI5OTFhNGE5LTM5YTAtNDQ0Mi04MWU4LWRkYjY4NTllMTg2MQC4AQIBAHhPj7k9zU4nGXUQUvM0Ccwk42DS-fm3vKmH75ktTrktNQG1gnjl6HkUVUYN1J_HPow6AAAAfjB8BgkqhkiG9w0BBwagbzBtAgEAMGgGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMulTha32s34j2CmQWAgEQgDtog8CDFh2e-4YyjM2kB_MXheMgmrdY_IF3aN9TImZXddMBj7djEAPPduLZnG3ddBLYQa8x3T3WPKUkvwIAAAAADAAAEAAAAAAAAAAAAAAAAADCbdmpLPo0E4QkWLlyH8ov_____wAAAAEAAAAAAAAAAAAAAAEAAAC1oMtgshmuUU4fk36WHKBzPgJEoE1MmL0PFyhR9lRcimImOIObhhxvC1fwiYylgbYx0Gu0i1cp5Le8AvrAnUGEJjZp54TMPP4N-JCT3qSrHeq_Kat_2CuECVSQqkc1qH4z9FVOTvAnos4FrDSn2W6KvFfLo8YQh2LJxM1h3GdIeyYqj7Ipfk6PZKGYmV5P741rRMNcuYBtvE8Hq9gVqMbEPG-c5MppY_q9JoG9TyQRN7rVGlZf62_WtTqST2F3-DZPoXTMTyY\u0026#34;， \u0026#34;challengeParameters\u0026#34;: { \u0026#34;USER_ID_FOR_SRP\u0026#34;: \u0026#34;shiun\u0026#34;， \u0026#34;requiredAttributes\u0026#34;: \u0026#34;[]\u0026#34;， \u0026#34;userAttributes\u0026#34;: \u0026#34;{\\\u0026#34;email\\\u0026#34;:\\\u0026#34;xxxxx@gmail.com\\\u0026#34;}\u0026#34; } } Cognito 回傳了一個 NEW_PASSWORD_REQUIRED 的 challenge，同時給了我們一個 session token。這就是我們需要處理的 case。\n解決方案 要解決這個問題，我們需要提供一個 change-password 的 API endpoint，讓 user 可以順利更改密碼。整個 flow 大致如下:\nUser 首次登入 Cognito 回傳 NEW_PASSWORD_REQUIRED challenge 和 session token 前端帶著 session token 呼叫我們的 change-password API 密碼更改成功，user 順利登入系統 以下是一個處理這種情況的 Lambda function 範例:\nimport json import logging import boto3 from botocore.exceptions import ClientError # Initialize logger logger = logging.getLogger() logger.setLevel(logging.INFO) # Initialize Cognito client client = boto3.client(\u0026#34;cognito-idp\u0026#34;) def lambda_handler(event, context): \u0026#34;\u0026#34;\u0026#34; Handles the NEW_PASSWORD_REQUIRED challenge from Cognito \u0026#34;\u0026#34;\u0026#34; try: # Parse the request body body = json.loads(event[\u0026#34;body\u0026#34;]) # Respond to the new password required challenge response = client.respond_to_auth_challenge( ClientId=\u0026#34;YOUR_CLIENT_ID\u0026#34;, ChallengeName=\u0026#34;NEW_PASSWORD_REQUIRED\u0026#34;, Session=body[\u0026#34;session\u0026#34;], ChallengeResponses={ \u0026#34;USERNAME\u0026#34;: body[\u0026#34;username\u0026#34;], \u0026#34;NEW_PASSWORD\u0026#34;: body[\u0026#34;new_password\u0026#34;], # Add any required attributes here if necessary }, ) logger.info(\u0026#34;Cognito respond to challenge response: %s\u0026#34;, response) # Extract access token from the response access_token = response[\u0026#34;AuthenticationResult\u0026#34;][\u0026#34;AccessToken\u0026#34;] # Return successful response with the access token set in cookies return { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;headers\u0026#34;: { \u0026#34;Set-Cookie\u0026#34;: f\u0026#34;accessToken={access_token}; Path=/; Secure; HttpOnly; SameSite=None; Domain=.aws-educate.tw\u0026#34; }, \u0026#34;body\u0026#34;: json.dumps({\u0026#34;message\u0026#34;: \u0026#34;Password changed successfully\u0026#34;}), } except ClientError as e: # Handle Cognito client errors logger.error(\u0026#34;Cognito client error: %s\u0026#34;, e) return { \u0026#34;statusCode\u0026#34;: 400, \u0026#34;body\u0026#34;: json.dumps({\u0026#34;message\u0026#34;: e.response[\u0026#34;Error\u0026#34;][\u0026#34;Message\u0026#34;]}), } except json.JSONDecodeError as e: # Handle JSON decoding errors logger.error(\u0026#34;JSON decode error: %s\u0026#34;, e) return { \u0026#34;statusCode\u0026#34;: 400, \u0026#34;body\u0026#34;: json.dumps({\u0026#34;message\u0026#34;: \u0026#34;Invalid JSON format in request body\u0026#34;}), } 這個 Lambda function 做了以下幾件事:\n接收包含 username、new password 和 session token 的 request 使用 Cognito 的 respond_to_auth_challenge API 來處理 NEW_PASSWORD_REQUIRED challenge 如果密碼更改成功，從 response 中提取 access token 將 access token 設置在 cookie 中，並返回成功訊息 透過這樣的處理，我們可以讓新用戶順利完成首次登入時的密碼更改流程，提供更好的 user experience。\n記得，在實際部署時，要根據你的具體需求來調整這個 function，比如錯誤處理、日誌記錄等。同時，也要確保前端能夠正確處理這個流程，在收到 NEW_PASSWORD_REQUIRED challenge 時，引導用戶到密碼更改的頁面。\n希望這個範例能幫助讀者更好地處理 AWS Cognito 的首次登入密碼更改流程\n","permalink":"https://shiun.me/blog/aws-cognito-how-to-handle-force-change-password/","summary":"情境描述 上圖顯示的是我剛在 Cognito User Pool 中新增了一個 user，可以注意到箭頭處顯示 Force change password。\n當這個 user 嘗試首次登入時，他們會遇到這樣的情況:\n{ \u0026#34;message\u0026#34;: \u0026#34;New password required\u0026#34;， \u0026#34;challengeName\u0026#34;: \u0026#34;NEW_PASSWORD_REQUIRED\u0026#34;， \u0026#34;session\u0026#34;: \u0026#34;AYABeAsYJsR3yEr0iJssKPPUPEgAHQABAAdTZXJ2aWNlABBDb2duaXRvVXNlclBvb2xzAAEAB2F3cy1rbXMAS2Fybjphd3M6a21zOnVzLXdlc3QtMjowMTU3MzY3MjcxOTg6a2V5LzI5OTFhNGE5LTM5YTAtNDQ0Mi04MWU4LWRkYjY4NTllMTg2MQC4AQIBAHhPj7k9zU4nGXUQUvM0Ccwk42DS-fm3vKmH75ktTrktNQG1gnjl6HkUVUYN1J_HPow6AAAAfjB8BgkqhkiG9w0BBwagbzBtAgEAMGgGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMulTha32s34j2CmQWAgEQgDtog8CDFh2e-4YyjM2kB_MXheMgmrdY_IF3aN9TImZXddMBj7djEAPPduLZnG3ddBLYQa8x3T3WPKUkvwIAAAAADAAAEAAAAAAAAAAAAAAAAADCbdmpLPo0E4QkWLlyH8ov_____wAAAAEAAAAAAAAAAAAAAAEAAAC1oMtgshmuUU4fk36WHKBzPgJEoE1MmL0PFyhR9lRcimImOIObhhxvC1fwiYylgbYx0Gu0i1cp5Le8AvrAnUGEJjZp54TMPP4N-JCT3qSrHeq_Kat_2CuECVSQqkc1qH4z9FVOTvAnos4FrDSn2W6KvFfLo8YQh2LJxM1h3GdIeyYqj7Ipfk6PZKGYmV5P741rRMNcuYBtvE8Hq9gVqMbEPG-c5MppY_q9JoG9TyQRN7rVGlZf62_WtTqST2F3-DZPoXTMTyY\u0026#34;， \u0026#34;challengeParameters\u0026#34;: { \u0026#34;USER_ID_FOR_SRP\u0026#34;: \u0026#34;shiun\u0026#34;， \u0026#34;requiredAttributes\u0026#34;: \u0026#34;[]\u0026#34;， \u0026#34;userAttributes\u0026#34;: \u0026#34;{\\\u0026#34;email\\\u0026#34;:\\\u0026#34;xxxxx@gmail.com\\\u0026#34;}\u0026#34; } } Cognito 回傳了一個 NEW_PASSWORD_REQUIRED 的 challenge，同時給了我們一個 session token。這就是我們需要處理的 case。\n解決方案 要解決這個問題，我們需要提供一個 change-password 的 API endpoint，讓 user 可以順利更改密碼。整個 flow 大致如下:\nUser 首次登入 Cognito 回傳 NEW_PASSWORD_REQUIRED challenge 和 session token 前端帶著 session token 呼叫我們的 change-password API 密碼更改成功，user 順利登入系統 以下是一個處理這種情況的 Lambda function 範例:","title":"如何使用 Lambda 處理 AWS Cognito User 首次登入被系統要求強制變更密碼"},{"content":"在 AWS API Gateway 創建 method 時，我們可以指定他要把請求傳到哪個 AWS 服務或是其他 HTTP Endpoint\u0026hellip;等等，而如果你選擇 Lambda，你會看到有一個選項是 Lambda Proxy Integration，那我把它勾選起來會怎樣呢？\nTL;DR 如果有打開 Lambda Proxy Integration，接著我們到那個 Resource 的 Method 頁面看一下，會看到下圖的提示 Proxy integration For proxy integrations, API Gateway automatically passes the backend output to the caller as the complete payload.\n但也許沒有很好理解，所以我們後面會實際打 Code 來示範，但我這邊先稍微解釋一下打開這個功能的影響:\n完整的 HTTP 請求資訊：啟用 Lambda Proxy Integration 後，API Gateway 會將整個 HTTP 請求打包成單一的 event object，並傳遞給 Lambda Function 簡化的處理流程：Lambda Function 接收到的是一個包含了所有請求資訊的 event object，因此不需要再通過模板或轉換就可以直接處理請求。這樣簡化了函數的輸入處理，因為 Lambda Function 已經包含了所有必要的請求資訊 控制 HTTP Response：Lambda Function 需要返回一個特定格式的物件，這個物件包括 Status Code、Response Headers 和 Response Body。由於 Response 是直接由 Lambda Function 生成的，所以開發者可以完全控制 Response 的格式和內容 效能和成本效益：由於請求處理的過程更加直接，減少了中間的處理和轉換步驟，可以提高處理效率，可能也會在某種程度上降低成本 總之，選擇 Lambda Proxy Integration 可以使得與 AWS Lambda 的整合更加緊密、直接和高效。這適合需要精細控制 HTTP 響應的場景，或者希望簡化 API 與 Lambda 之間交互的架構設計\n來看實際的例子先來感受有無開啟的行為差異 我現在創建了兩個 API Gateway -\u0026gt; Lambda 的組合:\n使用 Proxy Integration 不使用 Proxy Integration 而程式碼目前都是:\nimport json def lambda_handler(event, context): # TODO implement return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;Hello from Lambda!\u0026#39;) } 接著我們分別調用看看這兩支 API\nWith Lambda Proxy Integration # With Lambda Proxy Integration $ curl -X GET \u0026#34;https://m13nrn7ks1.execute-api.us-west-2.amazonaws.com/dev\u0026#34; \u0026#34;Hello from Lambda!\u0026#34; Non Lambda Proxy Integration # Non Lambda Proxy Integration $ curl -X GET https://byjlq9pv48.execute-api.us-west-2.amazonaws.com/dev/ {\u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;\\\u0026#34;Hello from Lambda!\\\u0026#34;\u0026#34;} 可以注意到，回傳的格式不太一樣，前者是回傳單純的字串，後者才是包在 Json 物件內而且還多了 statusCode 在 Response Body，具體原因後面會解釋\n修改 Lambda Function 內 Return 的 Status Code 我們緊接著來改一下 Lambda Function 的程式碼，我把 statusCode 改成 400，所以現在的完整程式碼如下:\nimport json def lambda_handler(event, context): # TODO implement return { \u0026#39;statusCode\u0026#39;: 400, # 修改這行 \u0026#39;body\u0026#39;: json.dumps(\u0026#39;Hello from Lambda!\u0026#39;) } 一樣我依序調用 API，但是我這邊改成用 Postman 去調用，這樣比較好閱讀和觀覽，請幫我注意下面兩張圖片的紅框處:\nWith Lambda Proxy Integration Non Lambda Proxy Integration 注意到了嗎？有沒有打開 Lambda Proxy Integration 其行為差異會如此大，若有開啟 Lambda Proxy Integration，那他會直接把你在 Function 內設定的 statusCode 映射到 Response 的 Status Code；而沒有開啟的話，他會把你的 statusCode 包在 Response Body 內，這樣的行為是不是很不直覺呢？\n加入 Query Parameters 接著我現在要在 API 調用時，加上 Query Parameter name=Shiun，並且我也修改了程式碼:\nimport json def lambda_handler(event, context): name = event[\u0026#34;queryStringParameters\u0026#34;][\u0026#34;name\u0026#34;] # 從 evnet object 取得 Query Parameter return { \u0026#39;statusCode\u0026#39;: 200, # 改回 200 \u0026#39;body\u0026#39;: json.dumps(f\u0026#39;Hello {name}!\u0026#39;) } 一樣我再次分別調用兩支 API\nWith Lambda Proxy Integration Non Lambda Proxy Integration 可以注意到，有使用 Lambda Proxy Integration 的正確接到值了；而另一個沒有開啟的則出現錯誤，錯誤很明顯就是他找不到對應的 Key\n加入自定義 Header 接下來我要在Lambda Function 中 return 自定義的 Header: X-Shiun-Custom-Header\u0026quot; : \u0026quot;test\u0026quot;\n也是一樣，我會分別調用這兩支 API，我們來觀察 Response Headers\nWith Lambda Proxy Integration Non Lambda Proxy Integration 觀察到兩者的差異了嗎？有啟用 Lambda Proxy Integration 的那支 API 會看到 Response Headers 裡面真的有回傳 X-Shiun-Custom-Header\u0026quot; : \u0026quot;test\u0026quot;\nLambda Proxy Integration 的工作原理 到底是什麼原因會出現這樣的行為差異呢？所以我們來看看 Lambda Proxy Integration 的工作原理\n啟用 Lambda Proxy Integration 後，API Gateway 會將整個 HTTP 請求(包括request headers, query string parameters, URL path variables, payload 和 API configuration data) 打包成單一的 event object，並傳遞給 Lambda 函數。這也解釋為什麼我 call API 如果帶了 Query Param ，我使用這種寫法 name = event[\u0026quot;queryStringParameters\u0026quot;][\u0026quot;name\u0026quot;] 能抓到 API 請求的 Query Parameter\n而這個 event object 實際長這樣:\n{ \u0026#34;resource\u0026#34;: \u0026#34;/my/path\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/my/path\u0026#34;, \u0026#34;httpMethod\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;header1\u0026#34;: \u0026#34;value1\u0026#34;, \u0026#34;header2\u0026#34;: \u0026#34;value1,value2\u0026#34; }, \u0026#34;multiValueHeaders\u0026#34;: { \u0026#34;header1\u0026#34;: [ \u0026#34;value1\u0026#34; ], \u0026#34;header2\u0026#34;: [ \u0026#34;value1\u0026#34;, \u0026#34;value2\u0026#34; ] }, \u0026#34;queryStringParameters\u0026#34;: { \u0026#34;parameter1\u0026#34;: \u0026#34;value1,value2\u0026#34;, \u0026#34;parameter2\u0026#34;: \u0026#34;value\u0026#34; }, \u0026#34;multiValueQueryStringParameters\u0026#34;: { \u0026#34;parameter1\u0026#34;: [ \u0026#34;value1\u0026#34;, \u0026#34;value2\u0026#34; ], \u0026#34;parameter2\u0026#34;: [ \u0026#34;value\u0026#34; ] }, \u0026#34;requestContext\u0026#34;: { \u0026#34;accountId\u0026#34;: \u0026#34;123456789012\u0026#34;, \u0026#34;apiId\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;authorizer\u0026#34;: { \u0026#34;claims\u0026#34;: null, \u0026#34;scopes\u0026#34;: null }, \u0026#34;domainName\u0026#34;: \u0026#34;id.execute-api.us-east-1.amazonaws.com\u0026#34;, \u0026#34;domainPrefix\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;extendedRequestId\u0026#34;: \u0026#34;request-id\u0026#34;, \u0026#34;httpMethod\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;identity\u0026#34;: { \u0026#34;accessKey\u0026#34;: null, \u0026#34;accountId\u0026#34;: null, \u0026#34;caller\u0026#34;: null, \u0026#34;cognitoAuthenticationProvider\u0026#34;: null, \u0026#34;cognitoAuthenticationType\u0026#34;: null, \u0026#34;cognitoIdentityId\u0026#34;: null, \u0026#34;cognitoIdentityPoolId\u0026#34;: null, \u0026#34;principalOrgId\u0026#34;: null, \u0026#34;sourceIp\u0026#34;: \u0026#34;IP\u0026#34;, \u0026#34;user\u0026#34;: null, \u0026#34;userAgent\u0026#34;: \u0026#34;user-agent\u0026#34;, \u0026#34;userArn\u0026#34;: null, \u0026#34;clientCert\u0026#34;: { \u0026#34;clientCertPem\u0026#34;: \u0026#34;CERT_CONTENT\u0026#34;, \u0026#34;subjectDN\u0026#34;: \u0026#34;www.example.com\u0026#34;, \u0026#34;issuerDN\u0026#34;: \u0026#34;Example issuer\u0026#34;, \u0026#34;serialNumber\u0026#34;: \u0026#34;a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1\u0026#34;, \u0026#34;validity\u0026#34;: { \u0026#34;notBefore\u0026#34;: \u0026#34;May 28 12:30:02 2019 GMT\u0026#34;, \u0026#34;notAfter\u0026#34;: \u0026#34;Aug 5 09:36:04 2021 GMT\u0026#34; } } }, \u0026#34;path\u0026#34;: \u0026#34;/my/path\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;HTTP/1.1\u0026#34;, \u0026#34;requestId\u0026#34;: \u0026#34;id=\u0026#34;, \u0026#34;requestTime\u0026#34;: \u0026#34;04/Mar/2020:19:15:17 +0000\u0026#34;, \u0026#34;requestTimeEpoch\u0026#34;: 1583349317135, \u0026#34;resourceId\u0026#34;: null, \u0026#34;resourcePath\u0026#34;: \u0026#34;/my/path\u0026#34;, \u0026#34;stage\u0026#34;: \u0026#34;$default\u0026#34; }, \u0026#34;pathParameters\u0026#34;: null, \u0026#34;stageVariables\u0026#34;: null, \u0026#34;body\u0026#34;: \u0026#34;Hello from Lambda!\u0026#34;, \u0026#34;isBase64Encoded\u0026#34;: false } 此外，啟用 Lambda Proxy Integration，你也必須遵守特定的 Output Format，你才能正確地把 Response 傳遞出去:\n{ \u0026#34;isBase64Encoded\u0026#34;: true|false, \u0026#34;statusCode\u0026#34;: httpStatusCode, \u0026#34;headers\u0026#34;: { \u0026#34;headerName\u0026#34;: \u0026#34;headerValue\u0026#34;, ... }, \u0026#34;multiValueHeaders\u0026#34;: { \u0026#34;headerName\u0026#34;: [\u0026#34;headerValue\u0026#34;, \u0026#34;headerValue2\u0026#34;, ...], ... }, \u0026#34;body\u0026#34;: \u0026#34;...\u0026#34; } 所以這邊也解釋了，為什麼設定好 statusCode、headers，我就能控制整個 Response 回應的 Status Code 和 Headers，這中間都是因為有了 Lambda Proxy Integration 幫我們簡化了這中間繁雜的配置，如果沒有 Lambda Proxy Integration，那我們就必須手動去 API Gateway 那邊設定 Mapping Template，配置起來相當麻煩。\n那我到底要不要打開 Lambda Proxy Integration? 我會高度推薦打開，因為你可以在程式碼那邊控制 Response，這我不認為不只是「簡化」，而是「大大降低管理複雜度」，我認為這是一個更佳的管理方式 (這邊是我的主觀感受，並不代表完全正確)。\n甚至有時候我都會直接果斷啟用 Lambda Proxy Integration，然後在 API Gateway 後面加一層 Lambda 專門做參數驗證再轉發到實際後端的 Lambda Function，而非選擇在 API Gateway 那邊做請求預處理或是參數驗證。但實際仍需要以本身的業務需求去挑出最佳的解決方案，這邊只是提供一個我認為對開發人員很友善的處理方式，而且這種方式你也可以在程式碼內做出高度客製化\n總而言之，如果你沒有使用 Lambda Proxy Integration，則需要在 API Gateway 中配置額外的轉換模板來處理輸入和輸出格式。\n希望這篇文章有幫助你更加了解 Lambda Proxy Integration 的功能和行為，並且能夠在實際應用中更好地使用這個功能！\nResources Using AWS API Gateway as Proxy to other HTTP Endpoints Set up Lambda proxy integrations in API Gateway - Amazon API Gateway ","permalink":"https://shiun.me/blog/understanding-lambda-proxy-integration/","summary":"在 AWS API Gateway 創建 method 時，我們可以指定他要把請求傳到哪個 AWS 服務或是其他 HTTP Endpoint\u0026hellip;等等，而如果你選擇 Lambda，你會看到有一個選項是 Lambda Proxy Integration，那我把它勾選起來會怎樣呢？\nTL;DR 如果有打開 Lambda Proxy Integration，接著我們到那個 Resource 的 Method 頁面看一下，會看到下圖的提示 Proxy integration For proxy integrations, API Gateway automatically passes the backend output to the caller as the complete payload.\n但也許沒有很好理解，所以我們後面會實際打 Code 來示範，但我這邊先稍微解釋一下打開這個功能的影響:\n完整的 HTTP 請求資訊：啟用 Lambda Proxy Integration 後，API Gateway 會將整個 HTTP 請求打包成單一的 event object，並傳遞給 Lambda Function 簡化的處理流程：Lambda Function 接收到的是一個包含了所有請求資訊的 event object，因此不需要再通過模板或轉換就可以直接處理請求。這樣簡化了函數的輸入處理，因為 Lambda Function 已經包含了所有必要的請求資訊 控制 HTTP Response：Lambda Function 需要返回一個特定格式的物件，這個物件包括 Status Code、Response Headers 和 Response Body。由於 Response 是直接由 Lambda Function 生成的，所以開發者可以完全控制 Response 的格式和內容 效能和成本效益：由於請求處理的過程更加直接，減少了中間的處理和轉換步驟，可以提高處理效率，可能也會在某種程度上降低成本 總之，選擇 Lambda Proxy Integration 可以使得與 AWS Lambda 的整合更加緊密、直接和高效。這適合需要精細控制 HTTP 響應的場景，或者希望簡化 API 與 Lambda 之間交互的架構設計","title":"深度解析 AWS API Gateway 的 Lambda Proxy Integration 功能"},{"content":" Terraform Import 簡介 Terraform Import 是 Terraform 中的一個功能，允許你將現有的基礎設施資源導入到 Terraform 的狀態文件中。這樣，你可以將已有的基礎設施與 Terraform 的配置文件同步，並開始使用 Terraform 來管理這些資源\n什麼時候需要用到 terraform import？ terraform import 並不是一個自動偵測 AWS 資源上的東西，然後自動幫忙寫程式碼的工具 如果你以前沒有使用任何 IaC 的工具，都是直接在 AWS Console 上管理和創建資源，但現在想要導入 IaC，然後把那些「現有資源」導入到 Terraform 來管理，那你就會需要用到 terraform import\nterraform import 的主要目的是將已經存在的基礎設施資源導入到 Terraform 的狀態文件中，這樣你就可以用 Terraform 來管理這些資源。例如，如果你有一個已經存在的 AWS EC2 實例，而你現在想開始用 Terraform 來管理它，你需要導入這個實例以便 Terraform 知道它的存在和當前狀態\nSynopsis $ terraform import [options] ADDRESS ID ADDRESS 是 Terraform 配置中資源的地址。例如，aws_instance.my_instance ID 是資源的唯一標識符，這個值根據不同的資源類型會有所不同。例如，對於 AWS EC2 實例，這個 ID 是實例的 ID（例如 i-1234567890abcdef0） Example $ terraform import aws_instance.my_instance i-1234567890abcdef0 data.aws_region.current: Reading... data.aws_availability_zones.available: Reading... data.aws_ami.ubuntu: Reading... aws_instance.aws_linux: Import prepared! Prepared aws_instance for import aws_instance.aws_linux: Refreshing state... [id=i-00066e5627229c90e] data.aws_region.current: Read complete after 0s [id=us-east-1] data.aws_availability_zones.available: Read complete after 1s [id=us-east-1] data.aws_ami.ubuntu: Read complete after 1s [id=ami-0f81732f07ce19b1c] Import successful! The resources that were imported are shown above. These resources are now in your Terraform state and will henceforth be managed by Terraform. Hands-on 到 AWS Console 創建資源\n我這邊創建了一台 EC2 Instance\n接著在 main.tf 加入以下程式碼:\nresource \u0026#34;aws_instance\u0026#34; \u0026#34;aws_linux\u0026#34; { } 打開 Terminal 使用 terraform import 來 import 現有的資源\n$ terraform import aws_instance.aws_linux i-00066e5627229c90e data.aws_region.current: Reading... data.aws_availability_zones.available: Reading... data.aws_ami.ubuntu: Reading... aws_instance.aws_linux: Import prepared! Prepared aws_instance for import aws_instance.aws_linux: Refreshing state... [id=i-00066e5627229c90e] data.aws_region.current: Read complete after 0s [id=us-east-1] data.aws_availability_zones.available: Read complete after 1s [id=us-east-1] data.aws_ami.ubuntu: Read complete after 1s [id=ami-0f81732f07ce19b1c] Import successful! The resources that were imported are shown above. These resources are now in your Terraform state and will henceforth be managed by Terraform. 用 terraform state list 查看一下現在的 state，會看到我們的 aws_instance.aws_linux\n輸入看看 terraform plan :\n$ terrafomr plan ╷ │ Error: Missing required argument │ │ with aws_instance.aws_linux, │ on main.tf line 263, in resource \u0026#34;aws_instance\u0026#34; \u0026#34;aws_linux\u0026#34;: │ 263: resource \u0026#34;aws_instance\u0026#34; \u0026#34;aws_linux\u0026#34; { │ │ \u0026#34;launch_template\u0026#34;: one of `ami,instance_type,launch_template` must be specified ╵ ╷ │ Error: Missing required argument │ │ with aws_instance.aws_linux, │ on main.tf line 263, in resource \u0026#34;aws_instance\u0026#34; \u0026#34;aws_linux\u0026#34;: │ 263: resource \u0026#34;aws_instance\u0026#34; \u0026#34;aws_linux\u0026#34; { │ │ \u0026#34;ami\u0026#34;: one of `ami,launch_template` must be specified ╵ ╷ │ Error: Missing required argument │ │ with aws_instance.aws_linux, │ on main.tf line 263, in resource \u0026#34;aws_instance\u0026#34; \u0026#34;aws_linux\u0026#34;: │ 263: resource \u0026#34;aws_instance\u0026#34; \u0026#34;aws_linux\u0026#34; { │ │ \u0026#34;instance_type\u0026#34;: one of `instance_type,launch_template` must be specified 出現 ERROR 很正常，畢竟就是看著我們的程式碼去執行該指令，而我們的 resource \u0026quot;aws_instance\u0026quot; \u0026quot;aws_linux\u0026quot; {} 裡面都沒配置任何參數當然會出錯，要解決可以用 terraform state show 來處理，把這個資源的詳細資訊配置到我們程式碼，因為我們已經知道他被寫入 state\n使用 terraform state show 來查看資源的詳細資訊:\n$ terraform state show aws_instance.aws_linux # aws_instance.aws_linux: resource \u0026#34;aws_instance\u0026#34; \u0026#34;aws_linux\u0026#34; { ami = \u0026#34;ami-00beae93a2d981137\u0026#34; arn = \u0026#34;arn:aws:ec2:us-east-1:058264428816:instance/i-00066e5627229c90e\u0026#34; associate_public_ip_address = true availability_zone = \u0026#34;us-east-1b\u0026#34; cpu_core_count = 1 cpu_threads_per_core = 1 disable_api_stop = false disable_api_termination = false ebs_optimized = false get_password_data = false hibernation = false host_id = null # 略... 然後根據上面面 terraform state show 輸出的結果把程式碼改成如下:\n# main.tf resource \u0026#34;aws_instance\u0026#34; \u0026#34;aws_linux\u0026#34; { instance_type = \u0026#34;t2.micro\u0026#34; ami = \u0026#34;ami-00beae93a2d981137\u0026#34; } 接著再輸入 terraform plan 就不會報錯了，此時我們原先在 AWS Console 上手動建立了資源就被 Terraform 所管\n如果我們要刪掉那個資源也可以透過 terraform 來刪除，我們把原先那行註解掉:\n# main.tf # resource \u0026#34;aws_instance\u0026#34; \u0026#34;aws_linux\u0026#34; { # instance_type = \u0026#34;t2.micro\u0026#34; # ami = \u0026#34;ami-00beae93a2d981137\u0026#34; # } 接著我們再來執行 terraform plan :\n$ terraform plan # 略... # aws_instance.aws_linux will be destroyed # (because aws_instance.aws_linux is not in configuration) - resource \u0026#34;aws_instance\u0026#34; \u0026#34;aws_linux\u0026#34; { - ami = \u0026#34;ami-00beae93a2d981137\u0026#34; -\u0026gt; null - arn = \u0026#34;arn:aws:ec2:us-east-1:058264428816:instance/i-00066e5627229c90e\u0026#34; -\u0026gt; null - associate_public_ip_address = true -\u0026gt; null - availability_zone = \u0026#34;us-east-1b\u0026#34; -\u0026gt; null - cpu_core_count = 1 -\u0026gt; null 補充 - 直接寫在程式碼內，import block 在 Terraform v1.5.0 之後，引入了新的 import block，import block 可以直接在 Terraform 配置文件中指定哪些資源需要被導入，而不需要單獨執行 terraform import 命令\n這個新功能的好處在於，當你和你的團隊需要多次或系統地導入資源時，可以將這些導入操作版本化並包含在基礎設施即程式碼 (IaC) 配置中\n一個 import block 的基本語法如下:\nimport { to = aws_instance.example id = \u0026#34;i-12345678\u0026#34; } to 指定了要導入到的 Terraform 資源塊 id 是現有資源的 ID 所以剛才我們用 CLI 所示範的內容，你可以改成用以下方式來撰寫\nresource \u0026#34;aws_instance\u0026#34; \u0026#34;aws_linux\u0026#34; { # 你的資源配置 } import { to = aws_instance.example id = \u0026#34;i-00066e5627229c90e\u0026#34; } Resources Import | Terraform | HashiCorp Developer Shiun\u0026rsquo;s Learning Journal - 20240605 ","permalink":"https://shiun.me/blog/how-to-use-terraform-import-to-import-existing-resources-into-iac/","summary":"Terraform Import 簡介 Terraform Import 是 Terraform 中的一個功能，允許你將現有的基礎設施資源導入到 Terraform 的狀態文件中。這樣，你可以將已有的基礎設施與 Terraform 的配置文件同步，並開始使用 Terraform 來管理這些資源\n什麼時候需要用到 terraform import？ terraform import 並不是一個自動偵測 AWS 資源上的東西，然後自動幫忙寫程式碼的工具 如果你以前沒有使用任何 IaC 的工具，都是直接在 AWS Console 上管理和創建資源，但現在想要導入 IaC，然後把那些「現有資源」導入到 Terraform 來管理，那你就會需要用到 terraform import\nterraform import 的主要目的是將已經存在的基礎設施資源導入到 Terraform 的狀態文件中，這樣你就可以用 Terraform 來管理這些資源。例如，如果你有一個已經存在的 AWS EC2 實例，而你現在想開始用 Terraform 來管理它，你需要導入這個實例以便 Terraform 知道它的存在和當前狀態\nSynopsis $ terraform import [options] ADDRESS ID ADDRESS 是 Terraform 配置中資源的地址。例如，aws_instance.my_instance ID 是資源的唯一標識符，這個值根據不同的資源類型會有所不同。例如，對於 AWS EC2 實例，這個 ID 是實例的 ID（例如 i-1234567890abcdef0） Example $ terraform import aws_instance.","title":"要導入 IaC？用 Terraform Import 導入現有資源"},{"content":" 比賽簡介 這場比賽是 DIGITIMES 主辦，AWS 作為技術支援，總共邀請六個企業來命題，分為黑客組和創意交流組（簡單來說就是技術和非技術組），而黑客組在這場比賽必須使用 AWS 相關的服務和模型依照企業命題打造出 LLM Application 比賽前 賽前工作坊 在比賽前，比賽主辦方有舉辦多場賽前工作坊，讓我們熟悉 AI 技術，而我只要有空都有去參加，我把我在的工作坊的學習筆記都寫在我的 Notion 日誌\n2024/04/27 - 基礎 AI 工作坊 2024/04/28 - 基礎 AI 工作坊 2024/05/05 - 進階 AI 工作坊 (這場有 GameDay) 2024/05/07 - Gogoro 企業數據工作坊 其實 AI 這領域真的不是我的專長領域，我自己會開始開發 GenAI 應用是從加入伊雲谷後開始的，在伊雲谷執手的專案就是一個 LLM Application，加上 GenAI 話題真的是時下最火熱的話題，活在這時代，開發的日常要不碰到 AI 真的蠻難的\n而賽前工作坊的主講者們真的人都很好，講解的也都很清楚，特別感謝 Roger 和 Ginny 在工作坊的教導，以及 Scott 在 GameDay 當天賽後的支援，在賽前工作坊也和現場的人交流，認識了不少技術高手！\n比賽還沒開始，但光是前面的工作坊就覺得這次的參賽體驗真的很棒，賽前能跟這些技術大神學習，真的是一次難得的機會。\n比賽題目公布 在報名時是要填寫競賽主題的志願序的，我們當初投的第一個志願是「智慧應用」第二為「智慧移動 - Gogoro」，最終我們被安排在智慧移動的組別。\n而我們這組的題目如下: 官方提供的數據就是 Gogoro 官網上的車主手冊: https://support.gogoro.com/tw/manual/collections/236738689176894/\n基本上這個命題絕對逃不過 \u0026ldquo;RAG\u0026rdquo;\n這個題目有幾個難點:\n如何讓 LLM 回應圖片並且顯示出來? 車主手冊有很大的比例是圖片，如何把圖片 Embed? 車主手冊全是 pdf 檔，如何萃取出 pdf 檔內的圖片 當使用者提供的資訊不夠詳細，LLM 這邊應要求使用者提供更多資訊 何謂資訊足夠詳細? 該如何定義「是否詳細」 LLM 要怎麼知道還需要請使用者提供哪些額外資訊? 作戰會議 而在 2024/05/07 Gogoro 數據工作坊一結束，我們隊伍就馬上來開了第一場作戰會議，一直到比賽開始前，總共開了三次會議，我們大致把整個應用的架構想出來，以及要使用的技術棧都定義出來並做好分工。\n分工部分:\nYuna (隊長): 資料前處理及構建 Data Pipeline Richie: 資料前處理及構建 Data Pipeline Eason: Presentaion 及 Prompt 研究 Toby: 自動化將資料 Embedding ，然後自動化將向量儲存到 OpenSearch，以及利用 Gradio 構建介面 Shiun (我): LangChain 開發及部署 LLM 應用 架構部分應該看得出來我在部落格這裡塞不下，因此直接附上連結 (連結點我)，這邊所看到的架構圖只是我們會議討論時方便討論而畫出來的，但最後成品的架構其實跟這邊不太一樣，後面會提到最終的架構 另外想提一下，其實自己在開發 LLM 應用時，我很喜歡使用 Prompt Flow 來構建整個 Flow，雖然這是開源的，但這個終究是微軟的，所以最後這場比賽沒選擇使用 Prompt Flow XD，改成使用 LangGraph\n比賽前夕 我原本打算要用 LangGraph + LangChain 的組合來開發，但我花了三天學完 LangGraph 之後，發現自己真的沒有頭緒，用起來很力不從心，所以在比賽的前一晚我放棄使用 LangGraph，改成純用 Lambda 來構建出一個 Flow。\n而我擔心黑客松 30 個小時做不完，我在比賽的前一晚目標就是先開發出一個可以動的應用，然後在黑客松兩天串隊友們的資源。\n簡單來說，比賽前一晚我的目標是:\n串接 OpenSearch 實現 RAG 用 DynamoDB 儲存聊天紀錄，並確保 LLM 應用是具上下文記憶能力 IaC，確保黑客松當天直接一鍵部署，我是使用 AWS SAM 等最後弄完之後，大概早上 6:00 了，當時身體是累的但是睡不太著，然後就去買早餐，和隊友集合，然後去比賽啦\n其實當天我有開 Youtube 線上直播想要把黑客松前一晚的過程記錄起來\u0026hellip; 沒想到我 OBS 串流打開了，但是卻忘了按下「開始直播」\u0026hellip;一直到早上和隊友集合，隊友才告訴我我的 Youtube 畫面都是「等待中」\u0026hellip;\n比賽 Day1 - 一整天在 502 Bad Gateway 度過 早上和隊員一同進場報到 提案 在比賽剛開始時，評審會到各隊先看我們的初步提案給予我們建議，以我們這組「智慧移動 - Gogoro」來說，評審有: Gogoro 副總, Gogoro 資訊技術總監, Gogoro 資料科學家, AWS Sr. SA，但 Day1 提案的時候印象中是沒看到副總出席，而我們這隊就是把架構圖展示給評審看，同時也告訴我們遇到的難點。\n這個題目有幾個難點:\n如何讓 LLM 回應圖片並且顯示出來? 車主手冊有很大的比例是圖片，如何把圖片 Embed? 車主手冊全是 pdf 檔，如何萃取出 pdf 檔內的圖片 當使用者提供的資訊不夠詳細，LLM 這邊應要求使用者提供更多資訊 何謂資訊足夠詳細? 該如何定義「是否詳細」 LLM 要怎麼知道還需要請使用者提供哪些額外資訊? 當時我們只有請教評審們難點 4 的建議處理方式，而評審建議我的可以使用 Chain of Thought (CoT)\n開始卡在 502 Bad Gateway 在比賽才剛開始，我便遇到 502 Bad Gateway，明明早上 6.7 點左右都還 run 得好好的，現在 run 就會 502 Bad Gateway， 當時我遇到的 ERROR 如下:\n# 2024-05-18T01:29:19.802+-8:00 [ERROR] TypeError: not all arguments converted during string formatting Traceback (most recent call last): File \u0026#34;/var/task/is_question_relevant.py\u0026#34;, line 186, in lambda_handler response = retrieval_chain.invoke( # 略 當時我印象中我是為了使用 LangSmith 來方便追蹤我的 Chain，所以在 template.yaml 為 Lambda Function 配置了一些 LangChain 相關的環境變量，所以我當時對於程式碼是沒有任何改動的，完全就是在配置一些額外的環境變量，我完全不覺得設環境變量會造成錯誤。\n於是我就開始退 commit，一個一個慢慢往前追溯是哪邊開始造成的，最後把 template.yaml 的變更都捨棄 (也就是我配置環境變量那部分)，才發現就是真的因為配置了 LangChain 的環境變量導致發生錯誤\n以 OpenSearch Similarity Score Threshold 決定問題是否相關 在我們的架構中，有一個節點負責判斷用戶的問題是否與 Gogoro 的主題相關。如果問題不相關，我們會禮貌地拒絕回答。我們的策略是，當用戶的提問進來時，就我們會結合 Chat History 一起去做 Embedding 然後進行 Retrieval。我們設定了一個相似度分數閾值 (Similarity Score Threshold)，只有當文檔的 Similarity Score 高於這個閾值時，文檔才會被檢索出來。因此當沒有檢索到任何文檔，我們就可以判定用戶的提問是不相關的。\n而我們在 LangChain 官方文檔有看到這部分有 API 可以用，寫法會長這樣:\nretriever = db.as_retriever( search_type=\u0026#34;similarity_score_threshold\u0026#34;, search_kwargs={\u0026#34;k\u0026#34;: 3, \u0026#34;score_threshold\u0026#34;: 0.8}, ) docs_retrieved = retriever.invoke(query) for doc in docs_retrieved: print(\u0026#34;-\u0026#34; * 80) print(doc.page_content) print(\u0026#34;-\u0026#34; * 80) 但是很可惜我們稍早已經測試過，實際用下去就是會看到 NotImplementedError，簡單來說就是 LangChain 還沒有支援 OpenSearch 使用這個 similarity_score_threshold:\nBased on the information you\u0026rsquo;ve provided and the context from the LangChain repository, it seems like you\u0026rsquo;re encountering a NotImplementedError when trying to use the similarity_score_threshold search type with the OpenSearch retriever in LangChain. This is likely because the similarity_score_threshold search type is not currently supported in the OpenSearch retriever in the LangChain framework, as mentioned in this issue.\n資料來源: https://github.com/langchain-ai/langchain/issues/13007\n所以在這部分，只能放棄使用 LangChain，改成用原生的 Python 庫 opensearch-py，而很感謝我們隊員 Toby 對這部分還算熟悉，Toby 在比賽前幾日就有用過 opensearch-py 實踐 RAG (Toby 的 GitHub Repo 連結)，所以我省了很多研究時間。\n而別以為我們現在看起來很順利，我們雖然 Retrieval 這部分已經沒問題了，但接下來要再把這部分用 LangChain 的 chain.invoke() 又開始卡關了，這次碰到的 ERROR 是:\n[ERROR] ValueError: Invalid input type \u0026lt;class \u0026#39;langchain_core.prompts.chat.ChatPromptTemplate\u0026#39;\u0026gt;. Must be a PromptValue, str, or list of BaseMessages. Traceback (most recent call last): File \u0026#34;/var/task/is_question_rpy\u0026#34;, line 219, in lambda_handler answer = bedrock_llm.invoke(prompt) File \u0026#34;/var/task/langchalanguage_models/chat_models.py159, in invoke [self._convert_input(input)], File \u0026#34;/var/task/langchalanguage_models/chat_models.py142, in _convert_input raise ValueError( 但可惜到這邊，已經晚上 6:30 左右了，所以參賽者就先回家了，而我今天一整天就是「始於 502, 終於 502」，人還沒睡覺然後第一天東西還沒辦法正常 run 心態簡直快崩潰\u0026hellip;\n一回到家心裡想著一定要把這解決才能睡，結果一到家一碰到床之後睜開眼已經是 Day2 早上 6:00\n比賽 Day2 - 可敬的對手 一時來的靈感 黑客組預計會在 Day2 14:40 結束比賽\nDay2 我早上 6:00 醒來，梳洗一下，也不知道為什麼\u0026hellip; 靈感很臨時來，突然覺得我想到 Day1 Bug 的解法了，馬上打開電腦試了一下，還真的解出來了。\n真的平常工作也是這樣，卡了一整天的 Bug，總是會在無意間想到解法，我也算這次很幸運這個臨感來的那麼快，在 Day2 的一早就馬上解決昨天的大難關，給 Day2 做了一個美好的開始。\n現在我們的系統可以說是可以動了，放下身上的重擔後，我就趕緊搭車去黑客松比賽現場與隊友會合了。\n將資源部署到黑客松的 AWS 帳號 其實在 Day1 所有開發的東西我都部署在自己的 AWS 帳號，因為整個專案我都是用 AWS SAM來建置和部署資源的，所以要把同樣的東西部署到別的 AWS 帳號相當容易。\n但當然也是沒那麼順利，過程我犯了一個很傻的錯誤，就是忘記把 samconfig.toml 裡面的 image_repositories 換掉，所以我切換到黑客松的環境後，輸入 sam deploy，我根本沒辦法 Push 新的 Image 上去 ECR，因為我現在的 Credential 就是沒權限去 Push Image 到我自己 AWS 帳號的 ECR\n我以為是黑客松的 AWS 環境給的 Credential 有問題，所以還跑去請教 AWS SA - Scott，結果 SA 一提點我就知道自己犯蠢 XD，真的很抱歉不小心打擾到 SA\n發現自己犯蠢後資源當然也部署上去了，只能說 IaC 真的讚！\nPresentation 接下來我們把資源全都部署好，Toby 用 Gradio 切了一個簡單的前端介面然後我再把前端部署上去我們的專案就大功告成了！\nEason 將會負責上台簡報，而我會負責操控電腦\n在這兩天的黑客松，Eason 一直在旁邊研究我們的系統以及跟我們釐清很多技術架構，然後為我們這兩天的成品做了一個很棒的簡報\n比賽 14:40 結束後，我們收到了 Gogoro 指定的問題，必須在等下的 Presentation 中進行 Live Demo。而我們「大使夢之隊」是「智慧移動」第一個要上台報告的隊伍。\n沒過多久後，就開始上台簡報了，只能說 Eason 的台風真的很穩，邏輯清晰，把我們系統的價值和架構表達得很清楚。另外當時很多大使來旁邊幫我們加油，到了 Live Demo 環節，我們第一題不知什麼原因就 Timeout 了，但網頁重整後又正常了，真的有 Live Demo 就一定要擺綠色乖乖\u0026hellip;而後面的幾個問題，我覺得都符合我們預期，但就是有發現我們系統的回應時間其實太久了，幾乎都 20 秒上下才完成。\n但整體來說，我覺得我們已經把我們想展示的東西都展示出來了。\n可敬的對手 在智慧移動這組中，我們遇到了一個勁敵——「富貴怎麼先走了」。他們的系統架構大概跟我們有七八成相似，但在前端的表現以及 LLM 的回應速度上，他們明顯勝出很多。當他們上台展示時，我們都非常佩服他們 LLM 的回應速度如此之快，前端頁面做得既舒服又有流暢的 Steaming，那個第一印象絕對是超越我們的。\n當時我就知道，他們很可能是這次比賽的第一名。比賽結果出爐前，對方也來和我們交流他們使用的技術。我們從賽前工作坊的 GameDay 就知道他們實力雄厚，因為他們那組在 GameDay 也拿了第一！\n上圖為「富貴怎麼先走了」當天的 Presentation\n最終結果也不出所料，「富貴怎麼先走了」贏得了智慧移動組的優勝！比賽結束後，我們和他們聊了聊，發現他們真的很厲害，分工相當明確，隊友間彼此都很信任。這次經驗讓我們學到了很多，也再次恭喜他們取得優勝！\n結語 這場比賽身邊的人都很看好我們的大使夢之隊，也很感謝大家來現場加油打氣和餵食，不過最後沒能取得優勝確實有些遺憾！尤其是「富貴怎麼先走了」這隊真的很強，讓我認識到自己的實力還有待提升。他們的成品也給了我很多啟發，讓我知道自己的系統有哪些可以改進的地方。\n這次比賽學到了很多，主辦方的賽前工作坊非常紮實，現場的 SA 技術支援也非常到位，透過和各隊的交流，我也學到了不少新的技巧。\n最後，真的超感謝隊友們。資料前處理部分，隊長 Yuna 和 Richie 真的是超級給力！Toby 本身在做 LLM 方面的研究，他在整個過程中提供了我心目中的 Best Practice！Eason 比賽全程在一旁觀察我們的開發，研究 Prompt 並釐清整體的系統架構，簡報時他更是把系統完整呈現出來！每個隊友都是核心，能和這樣的隊友在 30 個小時內打造出應用，真的是一段很有革命情感的經歷，希望之後還有機會能再一起組隊參賽。\n","permalink":"https://shiun.me/blog/2024-aws-genai-hackathon/","summary":"比賽簡介 這場比賽是 DIGITIMES 主辦，AWS 作為技術支援，總共邀請六個企業來命題，分為黑客組和創意交流組（簡單來說就是技術和非技術組），而黑客組在這場比賽必須使用 AWS 相關的服務和模型依照企業命題打造出 LLM Application 比賽前 賽前工作坊 在比賽前，比賽主辦方有舉辦多場賽前工作坊，讓我們熟悉 AI 技術，而我只要有空都有去參加，我把我在的工作坊的學習筆記都寫在我的 Notion 日誌\n2024/04/27 - 基礎 AI 工作坊 2024/04/28 - 基礎 AI 工作坊 2024/05/05 - 進階 AI 工作坊 (這場有 GameDay) 2024/05/07 - Gogoro 企業數據工作坊 其實 AI 這領域真的不是我的專長領域，我自己會開始開發 GenAI 應用是從加入伊雲谷後開始的，在伊雲谷執手的專案就是一個 LLM Application，加上 GenAI 話題真的是時下最火熱的話題，活在這時代，開發的日常要不碰到 AI 真的蠻難的\n而賽前工作坊的主講者們真的人都很好，講解的也都很清楚，特別感謝 Roger 和 Ginny 在工作坊的教導，以及 Scott 在 GameDay 當天賽後的支援，在賽前工作坊也和現場的人交流，認識了不少技術高手！\n比賽還沒開始，但光是前面的工作坊就覺得這次的參賽體驗真的很棒，賽前能跟這些技術大神學習，真的是一次難得的機會。\n比賽題目公布 在報名時是要填寫競賽主題的志願序的，我們當初投的第一個志願是「智慧應用」第二為「智慧移動 - Gogoro」，最終我們被安排在智慧移動的組別。\n而我們這組的題目如下: 官方提供的數據就是 Gogoro 官網上的車主手冊: https://support.gogoro.com/tw/manual/collections/236738689176894/\n基本上這個命題絕對逃不過 \u0026ldquo;RAG\u0026rdquo;","title":"學生時期的最後一場比賽: 2024 GenAI Hackathon 比賽紀錄"},{"content":" 前幾天寫了一篇 Serverless Framework 101，今天就來寫寫 AWS SAM 的教學，這兩個都是用來部署及管理 Serverless 應用的框架，兩者可以說是競爭對手關係！待之後有空再來寫一篇這兩個產品的比較\nPrerequisites 註冊 AWS 帳戶 建立 Admin IAM User 建立 access key ID and secret access key 安裝 AWS CLI 配置 AWS credentials 以上詳細內容請查看官方文檔: prerequisites\n安裝 AWS SAM CLI Mac 的用戶要注意一下，從 2023/9 開始，AWS 不會在維護 AWS SAM CLI 的 Homebrew Installer\n由於我現在是使用 Windows 作業系統的電腦，今天示範如何在 Windows 安裝 AWS SAM CLI\nWindows 安裝 Windows 安裝相當簡單，只要去官方文檔裡面下載 MSI File，接著無腦的 Next 按按按就裝好了 XD\n下載好之後，輸入指令 sam --version 檢查是否安裝成功\n$ sam --version SAM CLI, version 1.115.0 Windows 啟用 LongPathsEnabled 到這邊還沒有結束，對於 Windows 用戶，Windows 系統的最大路徑限制（MAX_PATH）通常是 260 個字符，請一定要啟用 LongPathsEnabled ，不然在 sam 的某些指令執行後會因為文件路徑過長出現 Error，例如: sam init\nStarting in Windows 10, version 1607, MAX_PATH limitations have been removed from common Win32 file and directory functions. However, you must opt-in to the new behavior.\n資料來源: Maximum Path Length Limitation - Win32 apps\n請你以系統管理員身分打開你的 Powershell，這邊我使用 Powershell 版本為 7.4.2\n輸入指令:\n$ New-ItemProperty -Path \u0026#34;HKLM:\\SYSTEM\\CurrentControlSet\\Control\\FileSystem\u0026#34; -Name \u0026#34;LongPathsEnabled\u0026#34; -Value 1 -PropertyType DWORD -Force LongPathsEnabled : 1 PSPath : Microsoft.PowerShell.Core\\Registry::HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\FileSystem PSParentPath : Microsoft.PowerShell.Core\\Registry::HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control PSChildName : FileSystem PSDrive : HKLM PSProvider : Microsoft.PowerShell.Core\\Registry 因為有些 process 可能在設置此鍵之前就已經緩存，為了讓系統上的所有應用程序識別這個鍵的值，請重新開機！\nHello World Application 建立一個 Project 首先我們先建立一個 Project\n$ sam init SAM CLI now collects telemetry to better understand customer needs. You can OPT OUT and disable telemetry collection by setting the environment variable SAM_CLI_TELEMETRY=0 in your shell. Thanks for your help! Learn More: https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-telemetry.html You can preselect a particular runtime or package type when using the `sam init` experience. Call `sam init --help` to learn more. Which template source would you like to use? 1 - AWS Quick Start Templates 2 - Custom Template Location Choice: 1 Choose an AWS Quick Start application template 1 - Hello World Example 2 - Data processing 3 - Hello World Example with Powertools for AWS Lambda 4 - Multi-step workflow 5 - Scheduled task 6 - Standalone function 7 - Serverless API 8 - Infrastructure event management 9 - Lambda Response Streaming 10 - Serverless Connector Hello World Example 11 - Multi-step workflow with Connectors 12 - GraphQLApi Hello World Example 13 - Full Stack 14 - Lambda EFS example 15 - DynamoDB Example 16 - Machine Learning Template: 1 Use the most popular runtime and package type? (Python and zip) [y/N]: y Would you like to enable X-Ray tracing on the function(s) in your application? [y/N]: Would you like to enable monitoring using CloudWatch Application Insights? For more info, please view https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch-application-insights.html [y/N]: Would you like to set Structured Logging in JSON format on your Lambda functions? [y/N]: Project name [sam-app]: aws-sam-101 Cloning from https://github.com/aws/aws-sam-cli-app-templates (process may take a moment) ----------------------- Generating application: ----------------------- Name: aws-sam-101 Runtime: python3.9 Architectures: x86_64 Dependency Manager: pip Application Template: hello-world Output Directory: . Configuration file: aws-sam-101\\samconfig.toml Next steps can be found in the README file at aws-sam-101\\README.md Commands you can use next ========================= [*] Create pipeline: cd aws-sam-101 \u0026amp;\u0026amp; sam pipeline init --bootstrap [*] Validate SAM template: cd aws-sam-101 \u0026amp;\u0026amp; sam validate [*] Test Function in the Cloud: cd aws-sam-101 \u0026amp;\u0026amp; sam sync --stack-name {stack-name} --watch 現在我們已經成功建立好專案\n我們進到裡面看一下\n$ cd aws-sam-101 $ tree │ .gitignore │ README.md │ samconfig.toml # 存參數 │ template.yaml # AWS 根據此檔案配置你的 Infra │ __init__.py │ ├─events │ event.json │ ├─hello_world │ app.py # 你的 Lanbda Function 寫在這 │ requirements.txt │ __init__.py │ └─tests │ requirements.txt │ __init__.py │ ├─integration │ test_api_gateway.py │ __init__.py │ └─unit test_handler.py __init__.py Build 接下來我們就要來打包我們專案了，但因為我想要使用 Python 3.11，所以我先到 template.yaml 把 Runtime 改成 3.11\n接著輸入以下指令\n$ sam build Starting Build use cache Manifest file is changed (new hash: 3298f13049d19cffaa37ca931dd4d421) or dependency folder (.aws-sam\\deps\\ab6747e1-a68c-4fab-ae91-fa1c4dcd23e1) is missing for (HelloWorldFunction), downloading dependencies and copying/building source Building codeuri: C:\\GitHub\\aws-sam-101\\hello_world runtime: python3.11 metadata: {} architecture: x86_64 functions: HelloWorldFunction Running PythonPipBuilder:CleanUp Running PythonPipBuilder:ResolveDependencies Running PythonPipBuilder:CopySource Running PythonPipBuilder:CopySource Build Succeeded Built Artifacts : .aws-sam\\build Built Template : .aws-sam\\build\\template.yaml Commands you can use next ========================= [*] Validate SAM template: sam validate [*] Invoke Function: sam local invoke [*] Test Function in the Cloud: sam sync --stack-name {{stack-name}} --watch [*] Deploy: sam deploy --guided 如指令 output 所示，你會發現你的 .aws-sam 目錄下多了 build 這個目錄\n.aws-sam ├── build │ ├── HelloWorldFunction │ │ ├── __init__.py │ │ ├── app.py # Lambda Function │ │ └── requirements.txt │ └── template.yaml └── build.toml Deploy 在這個部份，你需要配置你的 AWS Credentials，我已經事先創建好一個 IAM User 來暫時用，詳細如何配置你的 AWS Credentials 請自行翻閱官方文檔，本文預設讀者已具備操作 AWS 的基本能力\n輸入以下指令來部署你的 Lambda\n$ sam deploy --guided Configuring SAM deploy ====================== Looking for config file [samconfig.toml] : Found Reading default arguments : Success Setting default arguments for \u0026#39;sam deploy\u0026#39; ========================================= Stack Name [aws-sam-101]: AWS Region [ap-northeast-1]: #Shows you resources changes to be deployed and require a \u0026#39;Y\u0026#39; to initiate deploy Confirm changes before deploy [Y/n]: n #SAM needs permission to be able to create roles to connect to the resources in your template Allow SAM CLI IAM role creation [Y/n]: #Preserves the state of previously provisioned resources when an operation fails Disable rollback [y/N]: HelloWorldFunction has no authentication. Is this okay? [y/N]: y Save arguments to configuration file [Y/n]: SAM configuration file [samconfig.toml]: SAM configuration environment [default]: Looking for resources needed for deployment: Creating the required resources... Successfully created! Managed S3 bucket: aws-sam-cli-managed-default-samclisourcebucket-jptiw4noplqk A different default S3 bucket can be set in samconfig.toml and auto resolution of buckets turned off by setting resolve_s3=False Parameter \u0026#34;stack_name=aws-sam-101\u0026#34; in [default.deploy.parameters] is defined as a global parameter [default.global.parameters]. This parameter will be only saved under [default.global.parameters] in C:\\GitHub\\aws-sam-101\\samconfig.toml. Saved arguments to config file Running \u0026#39;sam deploy\u0026#39; for future deployments will use the parameters saved above. The above parameters can be changed by modifying samconfig.toml Learn more about samconfig.toml syntax at https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-config.html Uploading to aws-sam-101/37624213qqc910da9321690a64a28 554765 / 554765 (100.00%) Deploying with following values =============================== Stack name : aws-sam-101 Region : ap-northeast-1 Confirm changeset : False Disable rollback : False Deployment s3 bucket : aws-sam-cli-managed-default-samclisourcebucket-jptiw4noplqk Capabilities : [\u0026#34;CAPABILITY_IAM\u0026#34;] Parameter overrides : {} Signing Profiles : {} Initiating deployment ===================== Uploading to aws-sam-101/dbd54debe319zaa19577cbf2egaj4.template 1257 / 1257 (100.00%) Waiting for changeset to be created.. CloudFormation stack changeset ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Operation LogicalResourceId ResourceType Replacement ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- + Add HelloWorldFunctionHelloWorldPermissionPro AWS::Lambda::Permission N/A d + Add HelloWorldFunctionRole AWS::IAM::Role N/A + Add HelloWorldFunction AWS::Lambda::Function N/A + Add ServerlessRestApiDeployment47fcad5f9d AWS::ApiGateway::Deployment N/A + Add ServerlessRestApiProdStage AWS::ApiGateway::Stage N/A + Add ServerlessRestApi AWS::ApiGateway::RestApi N/A ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Changeset created successfully. arn:aws:cloudformation:ap-northeast-1:1234556781:changeSet/samcli-deploy17144221345/7ac52521a5-34ce-432f-bb1e-64521743e8g 2024-04-28 21:27:31 - Waiting for stack create/update to complete CloudFormation events from stack operations (refresh every 5.0 seconds) ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ResourceStatus ResourceType LogicalResourceId ResourceStatusReason ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- CREATE_IN_PROGRESS AWS::CloudFormation::Stack aws-sam-101 User Initiated CREATE_IN_PROGRESS AWS::IAM::Role HelloWorldFunctionRole - CREATE_IN_PROGRESS AWS::IAM::Role HelloWorldFunctionRole Resource creation Initiated CREATE_COMPLETE AWS::IAM::Role HelloWorldFunctionRole - CREATE_IN_PROGRESS AWS::Lambda::Function HelloWorldFunction - CREATE_IN_PROGRESS AWS::Lambda::Function HelloWorldFunction Resource creation Initiated CREATE_IN_PROGRESS AWS::Lambda::Function HelloWorldFunction Eventual consistency check initiated CREATE_IN_PROGRESS AWS::ApiGateway::RestApi ServerlessRestApi - CREATE_IN_PROGRESS AWS::ApiGateway::RestApi ServerlessRestApi Resource creation Initiated CREATE_COMPLETE AWS::ApiGateway::RestApi ServerlessRestApi - CREATE_IN_PROGRESS AWS::ApiGateway::Deployment ServerlessRestApiDeployment432d5f9d - CREATE_IN_PROGRESS AWS::Lambda::Permission HelloWorldFunctionHelloWorldPermissionPro - d CREATE_COMPLETE AWS::Lambda::Function HelloWorldFunction - CREATE_IN_PROGRESS AWS::Lambda::Permission HelloWorldFunctionHelloWorldPermissionPro Resource creation Initiated d CREATE_IN_PROGRESS AWS::ApiGateway::Deployment ServerlessRestApiDeployment4715f9d Resource creation Initiated CREATE_COMPLETE AWS::Lambda::Permission HelloWorldFunctionHelloWorldPermissionPro - d CREATE_COMPLETE AWS::ApiGateway::Deployment ServerlessRestApiDeployment12d5f9d - CREATE_IN_PROGRESS AWS::ApiGateway::Stage ServerlessRestApiProdStage - CREATE_IN_PROGRESS AWS::ApiGateway::Stage ServerlessRestApiProdStage Resource creation Initiated CREATE_COMPLETE AWS::ApiGateway::Stage ServerlessRestApiProdStage - CREATE_COMPLETE AWS::CloudFormation::Stack aws-sam-101 - ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- CloudFormation outputs from deployed stack -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Outputs -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Key HelloWorldFunctionIamRole Description Implicit IAM Role created for Hello World function Value arn:aws:iam::1234566781:role/aws-sam-101-HelloWorldFunctionRole-WAAUK9mx1X1E Key HelloWorldApi Description API Gateway endpoint URL for Prod stage for Hello World function Value https://ffj14dx1k.execute-api.ap-northeast-1.amazonaws.com/Prod/hello/ Key HelloWorldFunction Description Hello World Lambda Function ARN Value arn:aws:lambda:ap-northeast-1:1234567890:function:aws-sam-101-HelloWorldFunction-714agg15dlfg -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Successfully created/updated stack - aws-sam-101 in ap-northeast-1 當你看到 Successfully created/updated stack - aws-sam-101 in ap-northeast-1 就是完成囉\n我們到 AWS Console 查看一下 Lambda 和 CloudFormation\n而 sam deploy 這個指令背後執行的具體步驟如下:\n創建 S3 Bucket 並上傳 .aws-sam 目錄： AWS SAM CLI 首先創建一個 S3 Bucket（如果沒有指定現有的 Bucket）。這個 Bucket 用於存儲部署過程中需要的所有文件。 接著，AWS SAM CLI 將你的 .aws-sam 目錄上傳到這個新建的 S3 Bucket 中。.aws-sam 目錄通常包含編譯和打包後的應用程式碼及其依賴文件，這些是部署到 AWS 的必需資源。 將 AWS SAM 模板轉換為 AWS CloudFormation 並上傳： AWS SAM 模板是一種描述你的服務器無應用架構的文件，它使用 YAML 或 JSON 格式編寫。AWS SAM CLI 會將這個模板轉換成 AWS CloudFormation 模板。CloudFormation 是 AWS 提供的一個服務，允許用戶通過編寫模板來模型化和設定整個 AWS 資源堆棧。 轉換後的模板隨後被上傳到 AWS CloudFormation 服務。這個步驟是為了準備資源的配置和管理。 AWS CloudFormation 佈置資源： 一旦模板上傳到 AWS CloudFormation 服務，CloudFormation 便開始根據模板中的定義來創建和配置所需的 AWS 資源。這包括設定如函數、資料庫、網路設置等必要的組件。 CloudFormation 確保所有資源都按照模板中定義的依賴關係和參數設定正確部署，並管理資源的整個生命周期。 調用部署上去的 Lambda Function 現在我們可以來測試看看 API Endpoint，到剛剛的 Lambda，點擊 API Gateway 找到 Endpoint\n$ curl {YOUR_API_ENDPOINT} {\u0026#34;message\u0026#34;: \u0026#34;hello world\u0026#34;} 除了直接到 AWS Console 查看 API Endpoint 之外，sam 還有提供指令來查看 API Endpoints\n$ sam list endpoints --output json [ { \u0026#34;LogicalResourceId\u0026#34;: \u0026#34;HelloWorldFunction\u0026#34;, \u0026#34;PhysicalResourceId\u0026#34;: \u0026#34;aws-sam-101-HelloWorldFunction-7111ffa\u0026#34;, \u0026#34;CloudEndpoint\u0026#34;: \u0026#34;-\u0026#34;, \u0026#34;Methods\u0026#34;: \u0026#34;-\u0026#34; }, { \u0026#34;LogicalResourceId\u0026#34;: \u0026#34;ServerlessRestApi\u0026#34;, \u0026#34;PhysicalResourceId\u0026#34;: \u0026#34;123j013dx3i\u0026#34;, \u0026#34;CloudEndpoint\u0026#34;: [ \u0026#34;https://12313d13i.execute-api.ap-northeast-1.amazonaws.com/Prod\u0026#34;, \u0026#34;https://12313d13i.execute-api.ap-northeast-1.amazonaws.com/Stage\u0026#34; ], \u0026#34;Methods\u0026#34;: [ \u0026#34;/hello[\u0026#39;get\u0026#39;]\u0026#34; ] } ] 另外我們也可以使用 sam remote invoke 指令來調用部署 AWS 上的 Lambda\n但請特別注意，invoke 後面所接的參數，是你在 template.yaml 中所定義的 Resources 名稱，也就是 HelloWorldFunction，這跟 Serverless Framework 的 serverless invoke 指令概念一樣\n關於上述提到的 Serverless Framework，我有寫一篇教學文章，裡面有提到 serverless invoke 指令 (連結)\n$ sam remote invoke HelloWorldFunction Invoking Lambda Function HelloWorldFunction START RequestId: 1ec7cb08-1066-4f23-b4fd-b542a97ef27b Version: $LATEST END RequestId: 1ec7cb08-1066-4f23-b4fd-b542a97ef27b REPORT RequestId: 1ec7cb08-1066-4f23-b4fd-b542a97ef27b Duration: 2.30 ms Billed Duration: 3 ms Memory Size: 128 MB Max Memory Used: 33 MB Init Duration: 85.18 ms {\u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;{\\\u0026#34;message\\\u0026#34;: \\\u0026#34;hello world\\\u0026#34;}\u0026#34;} 對程式碼做個小更改，並快速部署最新變更至 AWS 現在我們來稍微修改一下 Lambda 程式碼，我把 hello world 改成 → hello shiun\n也許第一時間我們會想說可以用 sam deploy 這個指令把最新的變更部署上去，但是 AWS SAM CLI 還提供了一個指令 — sam snyc ，當正在開發 AWS Lambda 函數或其他 AWS 資源並且需要頻繁進行小的更改時，sam sync 可以讓您快速將這些更改推送到 AWS\nsam deploy vs sam sync sam sync 允許開發者快速將本地更改同步到已部署的應用，特別是對於代碼和配置的小修改。這對於快速開發周期非常有用，因為它大幅減少了等待時間，開發者可以即時看到他們更改的效果 只更新有變更的資源，避免了不必要的重複部署過程，這樣可以節省時間和成本，尤其是在開發階段的頻繁更新中 sam deploy： 進行完整的部署，包括重新打包應用、上傳到 S3，並通過 AWS CloudFormation 更新整個 Stack。這個過程通常比較耗時，對於小幅度的迭代來說可能效率不高 每次部署都可能涉及重建和重啟所有資源，即使是未更改的部分也一樣，這會導致更高的時間和成本消耗 綜合以上，我們這裡修改了程式碼，比較好的做法是使用 sam sync 指令來部署最新變更\n$ sam sync --watch The SAM CLI will use the AWS Lambda, Amazon API Gateway, and AWS StepFunctions APIs to upload your code without performing a CloudFormation deployment. This will cause drift in your CloudFormation stack. **The sync command should only be used against a development stack**. Confirm that you are synchronizing a development stack. Enter Y to proceed with the command, or enter N to cancel: [Y/n]: Y Queued infra sync. Waiting for in progress code syncs to complete... Starting infra sync. Manifest is not changed for (HelloWorldFunction), running incremental build Building codeuri: C:\\GitHub\\aws-sam-101\\hello_world runtime: python3.11 metadata: {} architecture: x86_64 functions: HelloWorldFunction Running PythonPipBuilder:CopySource Build Succeeded Successfully packaged artifacts and wrote output template to file C:\\Users\\Shiun\\AppData\\Local\\Temp\\tmpve9a9m2j. Execute the following command to deploy the packaged template sam deploy --template-file C:\\Users\\Shiun\\AppData\\Local\\Temp\\tmpveam2j --stack-name \u0026lt;YOUR STACK NAME\u0026gt; Deploying with following values =============================== Stack name : aws-sam-101 Region : ap-northeast-1 Disable rollback : False Deployment s3 bucket : aws-sam-cli-managed-default-samclisourcebucket-jptialqk Capabilities : [\u0026#34;CAPABILITY_NAMED_IAM\u0026#34;, \u0026#34;CAPABILITY_AUTO_EXPAND\u0026#34;] Parameter overrides : {} Signing Profiles : null Initiating deployment ===================== 2024-04-28 22:15:56 - Waiting for stack create/update to complete CloudFormation events from stack operations (refresh every 0.5 seconds) ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ResourceStatus ResourceType LogicalResourceId ResourceStatusReason ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- UPDATE_IN_PROGRESS AWS::CloudFormation::Stack aws-sam-101 User Initiated UPDATE_IN_PROGRESS AWS::CloudFormation::Stack aws-sam-101 Transformation succeeded CREATE_IN_PROGRESS AWS::CloudFormation::Stack AwsSamAutoDependencyLayerNestedStack - CREATE_IN_PROGRESS AWS::CloudFormation::Stack AwsSamAutoDependencyLayerNestedStack Resource creation Initiated CREATE_COMPLETE AWS::CloudFormation::Stack AwsSamAutoDependencyLayerNestedStack - UPDATE_IN_PROGRESS AWS::Lambda::Function HelloWorldFunction - UPDATE_COMPLETE AWS::Lambda::Function HelloWorldFunction - UPDATE_COMPLETE_CLEANUP_IN_PROGRESS AWS::CloudFormation::Stack aws-sam-101 - UPDATE_COMPLETE AWS::CloudFormation::Stack aws-sam-101 - ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- CloudFormation outputs from deployed stack -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Outputs -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Key HelloWorldFunctionIamRole Description Implicit IAM Role created for Hello World function Value arn:aws:iam::1234567890:role/aws-sam-101-HelloWorldFunctionRole-WAAUK9mx1X1E Key HelloWorldApi Description API Gateway endpoint URL for Prod stage for Hello World function Value https://g13i1111.execute-api.ap-northeast-1.amazonaws.com/Prod/hello/ Key HelloWorldFunction Description Hello World Lambda Function ARN Value arn:aws:lambda:ap-northeast-1:1234567890:function:aws-sam-101-HelloWorldFunction-7i6w81lfg -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Stack update succeeded. Sync infra completed. CodeTrigger not created as CodeUri or DefinitionUri is missing for ServerlessRestApi. Infra sync completed. 現在我們上去 AWS Console 查看一下 Lambda 和 CloudFormation 的變更\nLambda 已經成功修改這部分我想沒什麼問題，那 CloudFormation 的 Stack 顯示 \u0026ldquo;NESTED” 這是什麼？由於此文章主要以 AWS SAM 入門教學為主，我這邊簡單解釋：\n在 AWS CloudFormation 中，Nested Stack 就是在一個主要的 Stack（想像成一個大的項目列表）裡面，可以創建和管理多個小 Stack（就像是項目列表中的子列表）。這樣做的好處是，當你有很多相似的設置或配置需要重複使用時，你可以把這些配置做成一個小 Stack，然後在其他項目中引用它，這樣就不需要每次都重寫相同的配置，可以讓整個結構更清晰，也更容易管理。\n承上，由於這個特性，我們可以重用配置，這也是為什麼 sam sync 比較適合開發快速迭代，而且部署速度較快\n詳細請見 AWS 官方文檔: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-nested-stacks.html\n再次調用一次，看看變更\n$ curl {YOUR_API_ENDPOINT} {\u0026#34;message\u0026#34;: \u0026#34;hello shiun\u0026#34;} 透過 AWS SAM CLI 刪除部署在 AWS 上的資源 CloudFormation 的特性就是可以刪除 Stack 來把當初透過這個 Stack 創建出來的資源刪乾淨，而 AWS SAM 身為 CloudFormation 的拓展，也提供了 sam delete 這個指令來刪除該專案部署在雲端上的資源\n$ sma delete Are you sure you want to delete the stack aws-sam-101 in the region ap-northeast-1 ? [y/N]: y Do you want to delete the template file 3141123123abc82d45ef55faf04.template in S3? [y/N]: y - Deleting S3 object with key 4c36d2ab78169da9e38fe8339b80626a - Deleting S3 object with key bd8e9f5130e915b480c3b2279a8baedb.template - Deleting S3 object with key 21410647a9e8cabc82d45e5556b6a804.template - Deleting Cloudformation stack aws-sam-101 Deleted successfully 其他資源 Shiun Blog - Serverless Framework 101 - 輕鬆開發並快速部署你的 AWS Lambda AWS Workshop Studio - AWS SAM Serverless Patterns Collection AWS Docs - Working with nested stacks ","permalink":"https://shiun.me/blog/aws-sam-101/","summary":"前幾天寫了一篇 Serverless Framework 101，今天就來寫寫 AWS SAM 的教學，這兩個都是用來部署及管理 Serverless 應用的框架，兩者可以說是競爭對手關係！待之後有空再來寫一篇這兩個產品的比較\nPrerequisites 註冊 AWS 帳戶 建立 Admin IAM User 建立 access key ID and secret access key 安裝 AWS CLI 配置 AWS credentials 以上詳細內容請查看官方文檔: prerequisites\n安裝 AWS SAM CLI Mac 的用戶要注意一下，從 2023/9 開始，AWS 不會在維護 AWS SAM CLI 的 Homebrew Installer\n由於我現在是使用 Windows 作業系統的電腦，今天示範如何在 Windows 安裝 AWS SAM CLI\nWindows 安裝 Windows 安裝相當簡單，只要去官方文檔裡面下載 MSI File，接著無腦的 Next 按按按就裝好了 XD\n下載好之後，輸入指令 sam --version 檢查是否安裝成功","title":"AWS SAM 101 - 文長圖多！從安裝到部署你的 AWS Lambda"},{"content":"Serverless Framework 簡介 Serverless Framework 是一個開源的無服務器應用框架，它允許開發者快速建立、部署和管理在 AWS Lambda、Google Cloud Functions、Azure Functions 等雲平台上運行的無服務器應用。這個框架使用一個簡潔的配置文件（通常是 serverless.yml），在其中定義了應用的所有資源和設定，讓開發者可以專注於編寫業務邏輯而非管理基礎設施。\n安裝 Serverless Framework Prerequisites:\n需要有 npm，若你的電腦沒有 npm，請去下載 NodeJS $ npm install -g serverless 創建一個 Service $ serverless ? What do you want to make? AWS - Node.js - Starter AWS - Node.js - HTTP API AWS - Node.js - Scheduled Task AWS - Node.js - SQS Worker AWS - Node.js - Express API AWS - Node.js - Express API with DynamoDB AWS - Python - Starter \u0026gt; AWS - Python - HTTP API AWS - Python - Scheduled Task AWS - Python - SQS Worker AWS - Python - Flask API AWS - Python - Flask API with DynamoDB Other 輸入指令後透過方向鍵選取你要的 Template，本文將已 AWS - Python HTTP API 示範\n如果這些模板沒有你滿意的，可以到 serverless/examples 找你要的模板，然後指令輸入 serverless --template-url=https://github.com/serverless/examples/tree/v3/...\n? What do you want to call this project? serverless-framework-101 ✔ Project successfully created in serverless-framework-101 folder ? Register or Login to Serverless Framework Yes Logging into the Serverless Framework via the browser If your browser does not open automatically, please open this URL: https://app.serverless.com?client=cli\u0026amp;transactionId=x6r7NmzVa-ExeVdCyQZV2 ✔ You are now logged into the Serverless Framework ✔ Your project is ready to be deployed to Serverless Dashboard (org: \u0026#34;shiunchiu\u0026#34;, app: \u0026#34;serverless-framework-101\u0026#34;) 進入你的工作目錄，然後開啟 VS Code\n$ cd your-service-name $ code . 現在的目錄架構應該會長這樣\nC:. .gitignore handler.py README.md serverless.yml 配置 Provider 登入 AWS 帳號 請先登入你的 AWS 帳號\n到 Serverless Framework Dashboard 配置 Provider 按下 \u0026ldquo;Connect AWS Provider\u0026rdquo; 後，會跳轉到 AWS CloudFormation 頁面，直接下滑到底，打勾 “I acknowledge that AWS CloudFormation might create IAM resources with custom names.” → Create Stack 等待一下，等 Stack 創建好我們可以去看一下這個 Stack，其實他就是幫你自動創建一個 IAM Role Stack 創建好後，跳轉到 Serverless Framework Dashboard，就會看到創建好的 Provider\n寫好 Code，把你的 Code 部署到 AWS 當我們寫好 Code 之後，就要把 Code 部署到 AWS 上面，這部分就來教學如何透過 Serverless Framework CLI 來部署\n$ serverless deploy # or sls deploy Deploying serverless-framework-101 to stage dev (us-east-1, \u0026#34;serverless-framework-101-dev\u0026#34; provider) Warning: Serverless Framework observability features do not support the following runtime: python3.11 ✔ Serverless Framework\u0026#39;s Observability features being set up on your AWS account (one-time set-up). An email will be sent upon completion, or view progress within the Dashboard: https://app.serverless.com/shiunchiu/settings/integrations ✔ Serverless Framework Observability is enabled ✔ Service deployed to stack serverless-framework-101-dev (173s) dashboard: https://app.serverless.com/shiunchiu/apps/serverless-framework-101/serverless-framework-101/dev/us-east-1 endpoint: GET - https://1ibju7jfc9.execute-api.us-east-1.amazonaws.com/ functions: hello: serverless-framework-101-dev-hello (2 kB) 如果比較懶想使用 sls deploy 指令，但你又使用 Powershell ，有可能會如果看到這種輸出，這是因為 PowerShell 將 sls 誤認為是 Select-String 的別名，這是 PowerShell 中用於搜索字符串的內建命令。建議換個 git bash 或是就乖乖打完整指令\n$ sls deploy cmdlet Select-String at command pipeline position 1 Supply values for the following parameters: Path[0]: 到 AWS Console 查看部署結果 我們可以先到 Lambda 頁面，可以看到部署上去的 function\n因為 Serverless Framework 其實是透過 CloudFormation 來部署，現在我們到 CloudFormation 頁面查看，也會看到有新的 Stack\n調用 Lambda Function 當我們部署好之後，就可以來調用看看!\n$ serverless invoke -f hello { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;{\\\u0026#34;message\\\u0026#34;: \\\u0026#34;Go Serverless v3.0! Your function executed successfully!\\\u0026#34;, \\\u0026#34;input\\\u0026#34;: {}}\u0026#34; } 透過 serverless invoke 指令就可以調用我們部署上去的 Lambda\n但需要特別注意 -f 後面的值是要根據你在 serverless.yml 上面所配置的 function name 來設定，並非已經部署上去的 Lambda Function name\n現在我們上去 CloudWatch 看 Log，會看到我們剛剛的調用\n有時候我們會想要直接在 Local 看到 log，那可以剛剛的 serverless invoke 指令加上 --log ，這樣就不用到 AWS Console 查看了\n$ serverless invoke -f hello --log { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;{\\\u0026#34;message\\\u0026#34;: \\\u0026#34;Go Serverless v3.0! Your function executed successfully!\\\u0026#34;, \\\u0026#34;input\\\u0026#34;: {}}\u0026#34; } -------------------------------------------------------------------- START SERVERLESS_TELEMETRY.TZ.H4sIAPFVLWYC/43QMUoDQRTGcSO4wpYBEbcxhIAYmGVmZ+bNTDoFG7EzlSA6+2aWhGyyYTduIuIhvELO4B0EC4/gBSy8glELLYTYveLBx+8f1mEHEETmPRLDJCUCHRAjE0pMmjqQjnKPNmpXvqx9mfuqIllpx35elCPCKCPO12Tg87zodsO9X192XpHcjlNnSeVGzS0a8ziJguntbFBMoqdG2NKWKp6i4AoFGOtQayW4BKe4FYkRzVaK4JGjlhI48NRpzsAw7TMJic5k1g5XK/H3yuHB69v+Y+95l928vH8dPVwG18vgMgwWGq5AHP8DcdqRzBoEikQ50ESwhBNNVzkSoaSXVFum+MV25+yof3Lenzaih08JNZDwjHMljKCrmg5TipkU1BrnwKyXRGtrtHd+rPFwUhdoZ8Ni8gd7o7t5d/8BvrD25toBAAA= END Duration: 4.13 ms Memory Used: 57 MB Stream Logs 其實我們還可以讓我們的 Log 在 Terminal 串流，我會在 VS Code 開啟兩個 Terminal 來示範\n在 VS Code 打開一個 Terminal ( 快捷鍵: Ctrl + `)，然後輸入以下指令\n$ serverless logs -f hello --tail 我們再接著建立一個新的 Terminal，依照下圖所示按下 \u0026ldquo;+\u0026rdquo;\n配置一下 VS Code 版面，依照下圖拖曳 Terminal 到上面\n配置好版面，我們將使用下方的 Terminal 來調用 Lambda Function\n$ serverless invoke -f hello { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;{\\\u0026#34;message\\\u0026#34;: \\\u0026#34;Go Serverless v3.0! Your function executed successfully!\\\u0026#34;, \\\u0026#34;input\\\u0026#34;: {}}\u0026#34; } 直接看下方的 gif 圖感受一下吧！ (這 gif 圖長達 27s 敬請耐心等待)\n透過今天的教學，我們學習到如何透過 Serverless Framework 來部署及開發 AWS Lambda，Serverless Framework 提供了一種高效且靈活的方式來運行和管理無服務器應用！\n參考資料 Serverless Framework - Setting Up Serverless Framework With AWS Serverless Framework - Providers GitHub - serverless/examples ","permalink":"https://shiun.me/blog/serverless-framework-101/","summary":"Serverless Framework 簡介 Serverless Framework 是一個開源的無服務器應用框架，它允許開發者快速建立、部署和管理在 AWS Lambda、Google Cloud Functions、Azure Functions 等雲平台上運行的無服務器應用。這個框架使用一個簡潔的配置文件（通常是 serverless.yml），在其中定義了應用的所有資源和設定，讓開發者可以專注於編寫業務邏輯而非管理基礎設施。\n安裝 Serverless Framework Prerequisites:\n需要有 npm，若你的電腦沒有 npm，請去下載 NodeJS $ npm install -g serverless 創建一個 Service $ serverless ? What do you want to make? AWS - Node.js - Starter AWS - Node.js - HTTP API AWS - Node.js - Scheduled Task AWS - Node.js - SQS Worker AWS - Node.js - Express API AWS - Node.js - Express API with DynamoDB AWS - Python - Starter \u0026gt; AWS - Python - HTTP API AWS - Python - Scheduled Task AWS - Python - SQS Worker AWS - Python - Flask API AWS - Python - Flask API with DynamoDB Other 輸入指令後透過方向鍵選取你要的 Template，本文將已 AWS - Python HTTP API 示範","title":"Serverless Framework 101 - 輕鬆開發並快速部署你的 AWS Lambda"},{"content":"在準備 SAA 的過程中，我覺得最難的部分就是網路，這篇文章主要先介紹一下 IGW 和 NAT Gateway 的差異，接著介紹一些使用心得。\n另外分享一下活動，最近我們大使推出了一個「證照陪跑計畫」，可以透過這個活動拿到 50% 折價券、AWS 贈品、考照學習資源以及加入 DC 社群，一直招募到 2024/04/28，有興趣的讀者可以來報名！(報名表單連結)\nInternet Gateway (IGW) IGW 是一種允許 VPC 與 Internet 之間通訊的 VPC 組件。它能讓 VPC 內的資源如 EC2 Instance 直接訪問 Internet，同時也能讓 Internet 上的使用者訪問 VPC 內的資源。\n主要功能包括：\n雙向通訊支持：允許配有 Public IP 的 Instance 訪問 Internet，同時也能接收來自 Internet 的數據。 高度的可靠性和擴展性：確保無需用戶干預即可維持服務的持續可用。 NAT Gateway NAT Gateway 是一種網路地址轉換服務，允許 Private Subnet 中的 Instance 連接到 VPC 外部的服務，同時阻止外部服務主動連接這些實例。這種設計特別適合需要訪問 Internet 但不需要從 Internet 接受直接訪問的敏感或保密環境。\nNAT Gateway 價錢:\nNAT Gateway 收費 = NAT Gateway 開啟時間 USD 0.062 per Hour + 經過 NAT 資料處理費用 USD 0.062 per GB + (Optional) 跨 AZ 傳輸費用 0.02 per GB (發送+接收) 總而言之很貴，最新價錢請參考 AWS 官方\n主要功能包括：\n單向連接：保護實例不被直接從互聯網訪問，同時允許它們安全地訪問必要的外部資源。 高效的地址轉換：將出站流量從 Private IP 地址轉換為 NAT Gateway 的公共IP地址。 如果你覺得還是很難懂 NAT 是什麼，我這邊就以一個學生宿舍做個比喻吧！如果你是學生，你現在住在學生宿舍的 0413 房，你不想給別人知道你的房號是幾號。\n你如果想要寄信給芬蘭的聖誕老公公，那你這時候會寫好信，收件地址是聖誕老公公的住址這無庸置疑，但是寄件人地址，你會以學校警衛室做為地址，你會透過警衛室的名義來寄出，所以當聖誕老公公收到信件時，他會看到寄信來的是學校警衛室寄出的；接著聖誕老公公要回信給你，他會寄到學生宿舍的警衛室收，警衛室會再把這封信轉傳給你，總而言之你寄出去的信，都會以學校警衛室的名義發出去 (至於警衛為什麼會知道進來的信要轉發給誰？關鍵字: NAT Translation table)\n核心差異與選擇考量 訪問權限：IGW 允許雙向通訊，適合需要與 Internet 雙向交互的 Public Subnet 應用，而 NAT Gateway 只支持出站訪問，適用於需要保護的 Private Subnet 環境。 實例需求：每個 VPC 僅需一個 IGW，而每個 AZ 可能需要一個 NAT Gateway 來保證服務的高可用性。 成本影響：使用 IGW 不會產生額外費用，而 NAT Gateway 則根據創建和使用情況收取費用。 一些使用心得 如果你的資源不怕別人看或是給別人直接訪問也沒什麼差，就別用 NAT Gateway 了，因為很貴！！！ Public IP 0.12/天，除非 Instances 達到一個數量 ，大約是 25 台 Instances，才會跟 2 個 NAT Gateway 打平，那時再來考慮改成 NAT Gateway 可能就會划算一點 最新價錢請參考 AWS 官方\n真的需要每個 AZ 都開 NAT Gateway 嗎？以 Tokyo 這 Region 來說，你有需要 3 個 AZ 都開嗎? 我自己是覺得要達到高可用性，兩個就夠了，不然真的很花錢，對於一些小專案或是 PoC，只要一個 NAT 然後背後的 Instance 共用同一個 NAT Gateway 即可 推薦文章: AWS NAT Gateway 佈局和設定\n","permalink":"https://shiun.me/blog/internet-gateway-vs-nat-gateway/","summary":"在準備 SAA 的過程中，我覺得最難的部分就是網路，這篇文章主要先介紹一下 IGW 和 NAT Gateway 的差異，接著介紹一些使用心得。\n另外分享一下活動，最近我們大使推出了一個「證照陪跑計畫」，可以透過這個活動拿到 50% 折價券、AWS 贈品、考照學習資源以及加入 DC 社群，一直招募到 2024/04/28，有興趣的讀者可以來報名！(報名表單連結)\nInternet Gateway (IGW) IGW 是一種允許 VPC 與 Internet 之間通訊的 VPC 組件。它能讓 VPC 內的資源如 EC2 Instance 直接訪問 Internet，同時也能讓 Internet 上的使用者訪問 VPC 內的資源。\n主要功能包括：\n雙向通訊支持：允許配有 Public IP 的 Instance 訪問 Internet，同時也能接收來自 Internet 的數據。 高度的可靠性和擴展性：確保無需用戶干預即可維持服務的持續可用。 NAT Gateway NAT Gateway 是一種網路地址轉換服務，允許 Private Subnet 中的 Instance 連接到 VPC 外部的服務，同時阻止外部服務主動連接這些實例。這種設計特別適合需要訪問 Internet 但不需要從 Internet 接受直接訪問的敏感或保密環境。\nNAT Gateway 價錢:\nNAT Gateway 收費 = NAT Gateway 開啟時間 USD 0.","title":"AWS Internet Gateway vs NAT Gateway 及使用心得分享"},{"content":"EventBridge 簡介 EventBridge Scheduler 是 AWS 在 2022/11 推出的新服務，相較於傳統事件驅動的 EventBridge，新推出的 Scheduler 是時間驅動的一個服務，你可以很輕易的在上面設置一些排程任務去調用 AWS 的其他服務，截至 2024/04/06，官方文件是顯示可以調用 AWS 超過 270 種服務，就我目前使用下來的心得，真的是相當易用！\n常見的使用場景:\n自動調整服務容量: 如 Amazon ECS 任務的數量或今天要介紹的 Aurora Serverless V2 ACU (今天要示範的) 自動化維護任務: 定時啟動或停止 EC2 Instance，以節省成本或進行系統維護。 SasS 訂閱即將到期通知: 蠻多 SaaS 系統可能會需要在用戶快到期時發送信件通知客戶續訂 架構說明 關於本文，我會預設讀者們對於 AWS 有基本的操作能力和認識，對於一些較瑣碎的動作會省略不講解\n本文要教學的是排程每天固定時間，會透過 EventBridge Scheduler 調用 Lambda Function 然後將 Aurora Serverless V2 的 ACU 降低。\n關於這個動作，我們其實要拆解成兩個部分:\n用 Lambda 去調整 Aurora Serverless v2 ACU 用 EventBridge 去 Trigger Lambda 下圖是從 AWS 官方 Blog 下載下來的架構圖，純示意圖大概讓各位認識 EventBridge 和 Lambda 的配合 整體的步驟大概會是\n創建 IAM Role 創建 Lambda Function 創建 EventBridge Scheduler 創建 IAM Policy 及 IAM Role 這個 IAM Role 將會給我們的 Lambda Function 可以去讀取和修改 Aurora\n創建 IAM Policy { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;rds:DescribeDBClusters\u0026#34;, \u0026#34;rds:ModifyDBCluster\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:ap-northeast-1:784523829721:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:ap-northeast-1:784523829721:log-group:/aws/lambda/AdjustAuroraACU:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;logs:PutLogEvents\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:ap-northeast-1:784523829721:log-group:/aws/lambda/AdjustAuroraACU:log-stream:*\u0026#34; } ] } 創建 IAM Role，然後 Attach 剛才所創建的 Policy 創建完畢應該會類似下圖 創建 Lambda Function Runtime: Python 3.12 IAM Role: {你剛才創建的 IAM Role} import boto3 def lambda_handler(event, context): # Extract ACU configuration and cluster identifier from the event min_capacity = event.get(\u0026#39;min_capacity\u0026#39;) max_capacity = event.get(\u0026#39;max_capacity\u0026#39;) cluster_identifier = event.get(\u0026#39;cluster_identifier\u0026#39;) # Ensure cluster_identifier is provided if not cluster_identifier: print(\u0026#34;Error: \u0026#39;cluster_identifier\u0026#39; not provided in the event.\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 400, \u0026#39;body\u0026#39;: \u0026#34;\u0026#39;cluster_identifier\u0026#39; is required.\u0026#34; } # Modify the capacity for Aurora Serverless v2 modify_aurora_serverless_v2_capacity(cluster_identifier, min_capacity, max_capacity) def modify_aurora_serverless_v2_capacity(cluster_identifier, min_capacity, max_capacity): # Initialize the RDS client rds_client = boto3.client(\u0026#39;rds\u0026#39;) try: response = rds_client.modify_db_cluster( DBClusterIdentifier=cluster_identifier, ServerlessV2ScalingConfiguration={ \u0026#39;MinCapacity\u0026#39;: min_capacity, \u0026#39;MaxCapacity\u0026#39;: max_capacity }, ApplyImmediately=True ) print(f\u0026#34;Capacity update successful: {response}\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: f\u0026#34;Capacity updated to Min: {min_capacity}, Max: {max_capacity} for {cluster_identifier}\u0026#34; } except Exception as e: print(f\u0026#34;Error updating capacity: {e}\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 500, \u0026#39;body\u0026#39;: f\u0026#34;Error updating capacity for {cluster_identifier}: {e}\u0026#34; } 進到 Configuration - General Configuration 調整 Lambda Timeout，我這邊是改成 10s 創建 EventBridge Scheduler 搜尋 EventBridge 後進入該頁面，側邊選單點選 Scheduler/Schedules\n點擊 \u0026ldquo;Create Schedule\u0026rdquo;\n選擇 \u0026ldquo;Recurring schedule\u0026rdquo;\nTimezone: (UTC+8) Asia/Taipei Schedule Type: Cron-based schedule Cron Expression: 02 4 * * ? * (這邊請依照你想觸發的特定時間去更動) Next\nTarget Detail\nTarget API: Lambda Invoke: {選擇你剛才創建的 Lambda Function} Payload\n{ \u0026#34;cluster_identifier\u0026#34;: \u0026#34;demoAurora\u0026#34;, \u0026#34;min_capacity\u0026#34;: 1, \u0026#34;max_capacity\u0026#34;: 1.5 } Next\nPermisison: Create new role for this schedule\nCreate\n照著以上的步驟做到這裡就完成，照理來說應該就沒問題了\nTroubleshooting InvalidParameterCombination 這是我剛開始踩到的坑，原因是 Aurora Serverless V2 必須指定 ServerlessV2ScalingConfiguration\nYou can set the capacity of an Aurora DB instance with the ModifyDBCluster API operation. Specify the ServerlessV2ScalingConfiguration parameter.\nAWS Docs - What is Amazon EventBridge Scheduler?\n相關資料 AWS Docs - What is Amazon EventBridge Scheduler? AWS Docs - Managing Aurora Serverless v2 DB clusters ","permalink":"https://shiun.me/blog/how-to-schedule-aurora-serverless-v2-acu-adjustments-using-aws-lambda-and-eventbridge-scheduler/","summary":"EventBridge 簡介 EventBridge Scheduler 是 AWS 在 2022/11 推出的新服務，相較於傳統事件驅動的 EventBridge，新推出的 Scheduler 是時間驅動的一個服務，你可以很輕易的在上面設置一些排程任務去調用 AWS 的其他服務，截至 2024/04/06，官方文件是顯示可以調用 AWS 超過 270 種服務，就我目前使用下來的心得，真的是相當易用！\n常見的使用場景:\n自動調整服務容量: 如 Amazon ECS 任務的數量或今天要介紹的 Aurora Serverless V2 ACU (今天要示範的) 自動化維護任務: 定時啟動或停止 EC2 Instance，以節省成本或進行系統維護。 SasS 訂閱即將到期通知: 蠻多 SaaS 系統可能會需要在用戶快到期時發送信件通知客戶續訂 架構說明 關於本文，我會預設讀者們對於 AWS 有基本的操作能力和認識，對於一些較瑣碎的動作會省略不講解\n本文要教學的是排程每天固定時間，會透過 EventBridge Scheduler 調用 Lambda Function 然後將 Aurora Serverless V2 的 ACU 降低。\n關於這個動作，我們其實要拆解成兩個部分:\n用 Lambda 去調整 Aurora Serverless v2 ACU 用 EventBridge 去 Trigger Lambda 下圖是從 AWS 官方 Blog 下載下來的架構圖，純示意圖大概讓各位認識 EventBridge 和 Lambda 的配合 整體的步驟大概會是","title":"如何使用 AWS EventBridge Scheduler 及 Lambda 自動排程調整 AWS Aurora Serverless V2 ACU"},{"content":"前言 很多人在初學 Docker 時，通常都會知道 CMD 和 ENTRYPOINT 基本上可以互換，但又覺得很疑惑既然兩個指令能互換為什麼要提供兩個指令給我們用? 但其實這兩者是有一些差異的，今天這篇文章就是來帶你了解 Dockerfile 中的 CMD 和 ENTRYPOINT\nCMD vs ENTRYPOINT 我這邊準備了兩個 Dockerfile，分別使用了 CMD 和 ENTRYPOINT\nFROM ubuntu:22.04 CMD [ \u0026#34;echo\u0026#34;, \u0026#34;Hello from CMD\u0026#34; ] FROM ubuntu:22.04 ENTRYPOINT [ \u0026#34;echo\u0026#34;, \u0026#34;Hello from ENTRYPOINT\u0026#34; ] 接著 build 了兩個 docker image，分別取名為 docker-cmd, docker-entrypoint\n$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker-entrypoint latest fa8ea026cc54 12 days ago 77.9MB docker-cmd latest bd73abaca1f4 12 days ago 77.9MB CMD 會被覆寫、ENTRYPOINT 則不會 理應來說我用 docker-cmd 這個 image 啟動一個容器，會打印出 Hello from CMD，執行結果確實也是如此:\n$ docker run docker-cmd Hello from CMD 但我現在在 docker run 後面加上額外的命令\n例如我額外加上: echo \u0026ldquo;I am shiun\u0026rdquo; 後面額外多加的指令會直接覆蓋掉原本的 CMD 指令，CMD 中的命令就不會被執行: $ docker run docker-cmd echo \u0026#34;I am shiun\u0026#34; I am shiun 同樣在 docker run 後面附加額外命令，如果是 ENTRYPOINT，則不會被覆寫，但是會傳遞給 ENTRYPOINT 作為額外參數\n例如我額外加上: echo \u0026ldquo;I am shiun\u0026rdquo; 這邊額外加上的命令，會被作為參數傳遞給 ENTRYPOINT 命令 注意一下！在這邊的上下文，我所指的「參數」是傳達給命令的額外資訊，用於影響該命令的行為。 參數不一定是選項 （像是 -f 或 -p），它們也可以是其他命令或文本值\n$ docker run docker-entrypoint echo \u0026#34;I am shiun\u0026#34; Hello from ENTRYPOINT echo I am shiun 補充說明: 有注意到引號(\u0026quot;) 不見了嗎? 引號的目的是確保被包含的字符串作為一個整體被傳遞，而不是被看作多個由空格分隔的獨立參數，就像我們在 Python print(\u0026quot;I am shiun\u0026quot;) ， \u0026ldquo;I am shiun\u0026rdquo; 整句被雙引號包裹住，整句會被視為「一個」字串\n由上面的執行結果會看到，我們傳入了兩個參數到 ENTRYPOINT\necho I am shiun 因此 ENTRYPOINT 最後執行的指令其實是:\n$ echo Hello from ENTRYPOINT echo I am shiun 如果兩個同時使用， CMD 會被作為 ENTRYPOINT 的默認參數 這次我再創建一個新的 Dockerfile，我會在該 Dockerfile 內同時使用 CMD 和 ENTRYPOINT\nFROM ubuntu:22.04 CMD [ \u0026#34;echo\u0026#34;, \u0026#34;Hello from CMD\u0026#34; ] # CMD 和 ENTRYPOINT 誰前誰後不影響等下的結果 ENTRYPOINT [ \u0026#34;echo\u0026#34;, \u0026#34;Hello from ENTRYPOINT\u0026#34; ] # CMD 和 ENTRYPOINT 誰前誰後不影響等下的結果 然後我 build 了 Image，取名為 docker-cmd-entrypoint\n馬上來 run 一個容器看看結果:\n$ docker run docker-cmd-entrypoint Hello from ENTRYPOINT echo Hello from CMD 會發現 CMD 原本要執行的指令被當作參數傳遞給 ENTRYPOINT\n要注意的是！！！ CMD 是被當成默認參數傳遞給 ENTRYPOINT 注意！！！是默認(預設)，也就是如果你沒特別指定，那我就默認使用這個值的概念\n讓我們來看一下官方文件的說明:\nCommand line arguments to docker run will be appended after all elements in an exec form ENTRYPOINT, and will override all elements specified using CMD.\n官方文件: https://docs.docker.com/engine/reference/builder/#entrypoint\n因此 ENTRYPOINT 那邊最後實際執行的指令是:\n$ echo Hello from ENTRYPOINT echo Hello from CMD 同時使用 CMD 和 ENTRYPOINT，在 docker run 指令又加上額外的命令 這邊的情境一樣使用到 docker-cmd-entrypoint 這個 Image 但我這次執行 docker run 會在後方附上額外的命令\n完整的指令會長這樣: docker run docker-cmd-entrypoint echo \u0026quot;I am shiun\u0026quot;\n這邊可以先停下來思考一下，回顧前面，特別是官方說明的部分，猜猜看上面的指令執行結果會是如何\nCommand line arguments to docker run will be appended after all elements in an exec form ENTRYPOINT, and will override all elements specified using CMD.\n官方文件: https://docs.docker.com/engine/reference/builder/#entrypoint\n執行結果如下:\n$ docker run docker-cmd-entrypoint echo \u0026#34;I am shiun\u0026#34; Hello from ENTRYPOINT echo I am shiun 由此可知，docker run 後面所附加的額外命令，會覆蓋掉 CMD 的內容，而且會作為參數傳遞至 ENTRYPOINT\n總結 ENTRYPOINT 容器啟動時必須執行的命令 CMD 容器啟動時默認(預設)執行的命令 ENTRYPOINT, CMD 同時使用 CMD 的內容變成 ENTRYPOINT 默認參數 docker run 後面若有附加命令 會覆蓋掉 CMD 的內容，而且會作為參數傳遞至 ENTRYPOINT ","permalink":"https://shiun.me/blog/dockerfile-cmd-vs-entrypoint/","summary":"前言 很多人在初學 Docker 時，通常都會知道 CMD 和 ENTRYPOINT 基本上可以互換，但又覺得很疑惑既然兩個指令能互換為什麼要提供兩個指令給我們用? 但其實這兩者是有一些差異的，今天這篇文章就是來帶你了解 Dockerfile 中的 CMD 和 ENTRYPOINT\nCMD vs ENTRYPOINT 我這邊準備了兩個 Dockerfile，分別使用了 CMD 和 ENTRYPOINT\nFROM ubuntu:22.04 CMD [ \u0026#34;echo\u0026#34;, \u0026#34;Hello from CMD\u0026#34; ] FROM ubuntu:22.04 ENTRYPOINT [ \u0026#34;echo\u0026#34;, \u0026#34;Hello from ENTRYPOINT\u0026#34; ] 接著 build 了兩個 docker image，分別取名為 docker-cmd, docker-entrypoint\n$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker-entrypoint latest fa8ea026cc54 12 days ago 77.9MB docker-cmd latest bd73abaca1f4 12 days ago 77.9MB CMD 會被覆寫、ENTRYPOINT 則不會 理應來說我用 docker-cmd 這個 image 啟動一個容器，會打印出 Hello from CMD，執行結果確實也是如此:","title":"Docker 初學常見問題 - CMD vs ENTRYPOINT 兩者的差異與範例"},{"content":"我踩到了什麼坑 本文的背景延續自我之前的文章《一個專案需要多個 Dockerfile - 淺談建構上下文 (build context)》\n因為我們目前經手的專案會需要針對不同環境或是測試 Build 不同的 Image，為了讓目錄架構更具組織性且容易理解，我們根據不同的環境把各個環境的 Dockerfile, docker-compose.yaml, .sh 等等放在各個環境的目錄下，現在的目錄架構大概像這樣 ↓：\nE2Eproject/\r├── testenvironment1/\r│ └── Dockerfile\r├── testenvironment2/\r│ ├── docker-compose.yaml\r│ └── Dockerfile\r├── start-headless-tests.sh\r└── requirements.txt 由於我正在本地 Debug 這個專案，需要在本地運行 Docker-compose，我便很自然的執行 docker-compose -f ./cicd/headless/docker-compose.yaml up，結果 Docker 容器運行起來時，遇了一個錯誤：/bin/bash: /usr/src/app/cicd/headless/start-headless-tests.sh: No such file or directory。\n這個錯誤讓我想也想不透哪邊出錯，我一開始都是針對 Dockerfile 去做動作，但完全沒有用\n這邊就附上當時錯誤發生時的 Dockerfile 和 docker-compose.yaml，大家可以試著猜猜看是哪個環節導致錯誤！\nE2Eproject/cicd/headless/Dockerfile ↓\n# Dockerfile # Use the official Python base image from the DockerHub. FROM python:3.12 # Set the working directory within the container. WORKDIR /usr/src/app # 略..... # 略..... # 略..... # Copy all files from the current directory on the host to the working directory in the container. # This includes the application source code and any additional required files. COPY . /usr/src/app/ # Copy the start-tests.sh script into the container\u0026#39;s work directory. RUN chmod +x /usr/src/app/start-headless-tests.sh # The command to run the application. CMD [\u0026#34;/bin/bash\u0026#34;, \u0026#34;/usr/src/app/cicd/headless/start-headless-tests.sh\u0026#34;] E2Eproject/cicd/headless/docker-compose.yaml ↓\n# docker-compose.yaml version: \u0026#39;3\u0026#39; services: selenium-hub: # 略 ... chrome-node: # 略 ... E2Eproject: container_name: E2Eproject build: context: ../../ dockerfile: ./cicd/headless/Dockerfile args: NO_CACHE: ${NO_CACHE:-false} depends_on: - selenium-hub networks: - network-grid volumes: - .:/usr/src/app networks: network-grid: Docker Volume 介紹 (Bind Mount vs Volume) 圖片取自：https://docs.docker.com/storage/volumes/\n要解掉這個坑，會牽扯到 Docker Volume 的概念，但本篇踩坑紀錄不會做太深入的講解，就簡單介紹一下\n在 Docker 中，Volume 是用來持久化和共享數據的重要機制。大致上，我們可以將其分為兩類：Bind Mount 和 Volume。今天，我們不打算討論第三種類型，tmpfs mount，因為它與今天的話題不太相關。\nBind Mount 使用時機 Bind Mount 是一種將宿主機(Host)的文件或目錄掛載到容器中的方法。適合以下情況：\n開發階段：當你需要對程式碼進行快速迭代時，使用 Bind Mount 可以即時反映宿主機上的更改。 這也是為何我 Debug 時，使用 Bind Mount 的原因，因為我在 Host 上的改動可以立即顯現出來 但這不意味著 Bind Mount 不適合用在 Production 環境，只是 Bind Mount 會依賴宿主機(Host)目錄系統的結構，在安全和一致性上讓你更難處理 日誌文件的處理：將日誌文件直接掛載到宿主機，方便進行日誌的收集和分析。 Volume 使用時機 Volume 則是由 Docker 管理的一種更加隔離和安全的數據持久化方法，官方也推薦使用 Volumes，我這邊就節錄一小段 Docker 官方列舉的優點，詳細可以去看一下官方文件(連結)：\nVolumes are the preferred mechanism for persisting data generated by and used by Docker containers. While bind mounts are dependent on the directory structure and OS of the host machine, volumes are completely managed by Docker. Volumes have several advantages over bind mounts:\nVolumes are easier to back up or migrate than bind mounts. Volumes work on both Linux and Windows containers. You can manage volumes using Docker CLI commands or the Docker API. Volumes can be more safely shared among multiple containers. Volume drivers let you store volumes on remote hosts or cloud p -roviders, encrypt the contents of volumes, or add other functionality. New volumes can have their content pre-populated by a container. Volumes on Docker Desktop have much higher performance than bind mounts from Mac and Windows hosts. 然後我也列舉一些 Volume 適合的情境：\n生產環境：在生產環境中，我們更關注數據的持久化和安全，Volume 提供了更好的隔離。 不希望與宿主機的文件系統直接交互：當需要對數據進行持久化存儲，並且不希望與宿主機的文件系統直接交互時。 相比 Bind Mount，Volume 就不用擔心宿主機因為不同作業系統表示路徑的方式不太一樣，因為 Volume 由 Docker 完全管理，例如： Windows: C:/Users/shiun/Documents/my_folder Mac: C:/Users/shiun/Documents/my_folder Linux: /home/shiun/my_folder 為什麼會發生錯誤 首先一定要了解在 docker-compose.yaml 中，Bind Mount 在指定宿主機的目錄路徑時，路徑的相對路徑是基於 docker-compose.yaml 的所在目錄:\n# 略... volumes: - .:/usr/src/app # \u0026lt;docker-compose.yaml 所處當前目錄路徑\u0026gt;: \u0026lt;容器目標目錄路徑\u0026gt; 再回到我遇到的問題，原因其實很簡單：\n在我使用的 Dockerfile 中，我使用了 COPY . /usr/src/app/ 指令將文件從建構上下文中複製到容器內。 但是，當容器啟動時，docker-compose.yaml 中定義的 volume 又將我本地的 E2Eproject/cicd/headless 目錄掛載到了同一位置。 這導致了容器中的 /usr/src/app 目錄內容被覆蓋，而且 start-headless-tests.sh 腳本並不存在於 E2Eproject/cicd/headless 中，因此容器找不到這個文件，進而出現 /bin/bash: /usr/src/app/cicd/headless/start-headless-tests.sh: No such file or directory 解決方法 解決這個問題其實很簡單：\n註解掉或移除 docker-compose.yaml 的 volume 指令，每一次有 code 改動都重新 Build Image 這樣就不會有掛載覆蓋的問題，畢竟我再 Dockerfile 裡面就有把整個專案目錄 COPY 到 WORKDIR 修改 volumes 設定：將它改為 ../../，這樣就會掛載 E2Eproject 目錄，而不是僅僅掛載 E2Eproject/cicd/headless。 再次提醒，這邊的相對路徑是基於 docker-compose.yaml 的所在目錄 改好的樣子會像這樣：\nE2Eproject/cicd/headless/docker-compose.yaml ↓\n# docker-compose.yaml version: \u0026#39;3\u0026#39; services: # 略... # 略... # 略... E2Eproject: container_name: E2Eproject build: context: ../../ dockerfile: ./cicd/headless/Dockerfile args: NO_CACHE: ${NO_CACHE:-false} depends_on: - selenium-hub networks: - network-grid volumes: - ../../:/usr/src/app # 關鍵修改的地方 networks: network-grid: 當然後續我還有做一些簡單的細節調整，但就不多加贅述，也不影響本篇踩坑紀錄的內容\n若文章內容有誤，歡迎隨時連絡我！你們的回饋對我來說相當重要！\n也歡迎跟我交流或是分享你的想法\n","permalink":"https://shiun.me/blog/docker-overwriting-workdir-contents-with-bind-mounts-at-run-time/","summary":"我踩到了什麼坑 本文的背景延續自我之前的文章《一個專案需要多個 Dockerfile - 淺談建構上下文 (build context)》\n因為我們目前經手的專案會需要針對不同環境或是測試 Build 不同的 Image，為了讓目錄架構更具組織性且容易理解，我們根據不同的環境把各個環境的 Dockerfile, docker-compose.yaml, .sh 等等放在各個環境的目錄下，現在的目錄架構大概像這樣 ↓：\nE2Eproject/\r├── testenvironment1/\r│ └── Dockerfile\r├── testenvironment2/\r│ ├── docker-compose.yaml\r│ └── Dockerfile\r├── start-headless-tests.sh\r└── requirements.txt 由於我正在本地 Debug 這個專案，需要在本地運行 Docker-compose，我便很自然的執行 docker-compose -f ./cicd/headless/docker-compose.yaml up，結果 Docker 容器運行起來時，遇了一個錯誤：/bin/bash: /usr/src/app/cicd/headless/start-headless-tests.sh: No such file or directory。\n這個錯誤讓我想也想不透哪邊出錯，我一開始都是針對 Dockerfile 去做動作，但完全沒有用\n這邊就附上當時錯誤發生時的 Dockerfile 和 docker-compose.yaml，大家可以試著猜猜看是哪個環節導致錯誤！\nE2Eproject/cicd/headless/Dockerfile ↓\n# Dockerfile # Use the official Python base image from the DockerHub.","title":"Docker 踩坑紀錄 - 運行階段 Bind Mount 覆蓋 WORKDIR 的內容"},{"content":"報名流程 履歷及申請動機 本篇文章主要以「技術支援」這個角度來探討履歷準備的方向，當然！這當中肯定有很多方向也是其他職能也可以拿來參考用的。即便您第一志願不是「技術支援」職能，我仍然建議你繼續讀完！\n先來了解 Technical Support (技術支援)這個角色會做哪些事 技術工作坊上台演講並教學雲端技術 提供組內雲端技術的諮詢和建議 撰寫工作坊所需的技術教學文件及應用 履歷準備方向 了解技術支援這個角色會做哪些事，盡可能地在撰寫履歷時，使內容可以讓面試官覺得你很適合這個角色\n教學技術的經驗 上台演講的經驗 技術專案的經驗 有使用到 AWS 尤佳 內容可以和 Amazon 領導力準則掛勾 展現你在技術上的所專精的專業領域，例如：\nAI Data Analysis DevOps \u0026hellip; 展現你的 Leadership 和 Ownership\n量化你的成果\n雲端技術證照\n履歷常見錯誤 ❌ 履歷的大頭照可放可不放，但仍建議不要放，部分職位、傳統台商或特別要求則例外，原因如下： 避免因種族、膚色、人種\u0026hellip; 產生任何 Bias 篇幅過長，超過兩頁 技術方面寫的過多過雜、許多不必要的雜訊，例如： 您有提到您會 Flask, Django，那就不必列出你會 Python 把有碰過的技術都寫上去，例如： 僅用過 Java 印出過 \u0026ldquo;Hello World\u0026rdquo; 就在「技能」區塊寫 Java 把專精的技術寫上去就好，怎樣算是專精呢？只要您對於這個技術有信心給面試官隨便問 5 個 Why 你都有信心可以回答就寫上來 未量化你的各經歷的成果，例如： 你曾舉辦過技術工作坊，但你僅僅寫了你任期內舉辦了工作坊 更好的寫法是，你可以告訴我們你舉辦了幾人的 XXX 技術工作坊，觀眾對於您的講評評價高達 4.8/5 分 把自己描述成跨領域通才了，你應要把自己描述成一個專精 XX 技術領域的跨領域人才，例如： 因履歷投遞的職能是「技術支援」，你應該要讓自己成為一個「專精 XX 技術領域的雲端人才，同時附帶了活動規劃的跨領域優勢」 而非把自己寫的什麼都很會，讓人摸不清你到底是來投技術職能還是來投活動規畫職能，又或者讓人覺得你是一個通才 把其他人的貢獻寫在自己的履歷，例如： 你參與了某專案你僅負責後端開發，前端開發部分並非你做的，然而你卻在專案中的經歷寫到你使用了前端的 XXX 技術做了 XXX 功能 申請動機準備方向 申請動機這一塊就有比較多自由發揮的空間 以下就給出兩點簡單的小建議：\n展現您對於雲端技術的學習意願 有建設性的任期規劃 履歷審錄取，進到面試 履歷審查錄取後，就會進去面試這一大關，面試這一大關又分成兩小關\n團體面試 個人面試 面試不開放線上面試！\n當時我通過履歷審，收到的面試通知信件 ↓ 面試服裝 面試服裝沒有強制規定，建議上網搜尋 Smart Casual 穿搭！\n(當然並不是說沒有強制規定就可以穿夾腳拖短褲背心來)\n團體面試 以下題目部分僅供參考，並非每屆的形式、題目都會一模一樣！\n10 人一組，一組裡面一定會有「活動規劃」、「行銷規廣」、「技術支援」的人 一開始先輪流每人 1 分鐘的自我介紹 會有一個面試官在前面說題目，題目通常都是要準備一場活動，然後要我們這一組合作，在時限內從一開始的活動規劃，一直到最後宣傳圖文產出，最後把活動整體的內容和圖文報告給面試官聽 過程中，場邊會有多位面試官，審視大家在團隊中的表現 在尾聲，會再讓每個人輪流發言一次，要告訴面試官在剛剛的過程中自己扮演什麼角色，在團隊中有做出什麼貢獻，一樣限時 1 分鐘 團體面試的一些建議 在一開始時，大家一定都不認識彼此，要開始團隊討論時，往往需要有一個人來破冰，第一個說話的人確實會比較容易令人印象深刻 避免一直搶 Spotlight，想刻意讓大家關注到你，並非在團隊中講越多話就越能受到賞識，話過多但卻沒帶來實質效應可能會帶來反效果 事前訓練自己的表達能力與溝通能力，因為身為技術的你會發現當你要跨團隊與「活動規劃」、「行銷推廣」的組員溝通時，你用太專業的術語對方會聽不懂 個人面試 以下題目部分僅供參考，並非每屆的形式、題目都會一模一樣！\n在履歷審通過後，會收到一封錄取信，通常會在錄取信裡面提及個人面試的題目 題目會給你 AWS 的幾個服務，你挑一個服務，並且在當天給你 8 分鐘介紹 演講形式不拘，所以你要自備紙本講義也沒問題，但我看大多數人都是做 PPT 來介紹 會被安排到一個會議室，裡面有電視可以接你的電腦 (會議室內有 HDMI 線) 面試官會有兩位，以我當時報名 5th 為例：一個是 AWS 的正職、一個是 AWS 雲端大使 Team Lead 8 分鐘時間把服務講解完後，面試官會對你做一些 Q\u0026amp;A，通常會針對你的履歷和剛剛演講的內容來發問 個人面試的一些建議 (重要) 身為技術職能的雲端大使，因為我們在舉辦很多活動時，面對的聽眾很多都沒有專業雲端知識背景，或是雲端小白，如何把一個技術內容講的讓雲端小白都聽得懂的能力相當重要！ 你可以舉一些生活中的真實情境，例如： 我當時講解 DynamoDB ，我用「登入驗證」的這個真實情境，講解 DynamoDB 在這過程中發揮的作用 找一些身邊的朋友，最好找沒有雲端技術背景的人，講解一次給他聽，並汲取對方的回饋來改進 不要引用到一些太難的觀念或是內容 履歷真的不要亂寫，被問到一問三不知就尷尬了 了解 Amazon 領導力準則，在 Q\u0026amp;A 時，讓自己的故事可以跟領導力準則切合 描述自己的故事時善用 STAR 原則 常見問題 我已經把履歷投出去了，現在才看到這篇文章想要重新修改履歷怎麼辦? 直接重新投遞一次就好喔！再次提醒，記得履歷連結要設定成「公開」 報名連結: https://www.surveycake.com/s/DZk3O 面試當天有事，有辦法線上面試嗎? 不行，僅開放實體面試 面試是全英文嗎? 需要準備英文自我介紹嗎? 面試全程皆以中文為主 履歷有規定要用英文嗎? 中文英文皆可！ 結語 希望這篇文章可以幫助到每位想來參加 AWS Educate 雲端大使的人，在這過程中可以積累人脈，體驗外商文化，同時在雲端大使任內也會有其他合作專案像是 DGR, MKT，讓你真的參與 AWS 正職的真實工作環境中！\n6th 雲端大使報名連結: https://www.surveycake.com/s/DZk3O Instagram: https://www.instagram.com/awseducatestdambtw/ Facebook: https://www.facebook.com/awseducatestudentambassadortaiwan/ ","permalink":"https://shiun.me/blog/aws-educate-6th-cloud-ambassador-resume-and-interview-preparation/","summary":"報名流程 履歷及申請動機 本篇文章主要以「技術支援」這個角度來探討履歷準備的方向，當然！這當中肯定有很多方向也是其他職能也可以拿來參考用的。即便您第一志願不是「技術支援」職能，我仍然建議你繼續讀完！\n先來了解 Technical Support (技術支援)這個角色會做哪些事 技術工作坊上台演講並教學雲端技術 提供組內雲端技術的諮詢和建議 撰寫工作坊所需的技術教學文件及應用 履歷準備方向 了解技術支援這個角色會做哪些事，盡可能地在撰寫履歷時，使內容可以讓面試官覺得你很適合這個角色\n教學技術的經驗 上台演講的經驗 技術專案的經驗 有使用到 AWS 尤佳 內容可以和 Amazon 領導力準則掛勾 展現你在技術上的所專精的專業領域，例如：\nAI Data Analysis DevOps \u0026hellip; 展現你的 Leadership 和 Ownership\n量化你的成果\n雲端技術證照\n履歷常見錯誤 ❌ 履歷的大頭照可放可不放，但仍建議不要放，部分職位、傳統台商或特別要求則例外，原因如下： 避免因種族、膚色、人種\u0026hellip; 產生任何 Bias 篇幅過長，超過兩頁 技術方面寫的過多過雜、許多不必要的雜訊，例如： 您有提到您會 Flask, Django，那就不必列出你會 Python 把有碰過的技術都寫上去，例如： 僅用過 Java 印出過 \u0026ldquo;Hello World\u0026rdquo; 就在「技能」區塊寫 Java 把專精的技術寫上去就好，怎樣算是專精呢？只要您對於這個技術有信心給面試官隨便問 5 個 Why 你都有信心可以回答就寫上來 未量化你的各經歷的成果，例如： 你曾舉辦過技術工作坊，但你僅僅寫了你任期內舉辦了工作坊 更好的寫法是，你可以告訴我們你舉辦了幾人的 XXX 技術工作坊，觀眾對於您的講評評價高達 4.8/5 分 把自己描述成跨領域通才了，你應要把自己描述成一個專精 XX 技術領域的跨領域人才，例如： 因履歷投遞的職能是「技術支援」，你應該要讓自己成為一個「專精 XX 技術領域的雲端人才，同時附帶了活動規劃的跨領域優勢」 而非把自己寫的什麼都很會，讓人摸不清你到底是來投技術職能還是來投活動規畫職能，又或者讓人覺得你是一個通才 把其他人的貢獻寫在自己的履歷，例如： 你參與了某專案你僅負責後端開發，前端開發部分並非你做的，然而你卻在專案中的經歷寫到你使用了前端的 XXX 技術做了 XXX 功能 申請動機準備方向 申請動機這一塊就有比較多自由發揮的空間 以下就給出兩點簡單的小建議：","title":"如何成為 AWS Educate 雲端大使？履歷準備、面試技巧大公開"},{"content":"最近在寫 E2E 測試遇到一個問題，因 E2E 專案中，除了專案本身的 Docker Image 需要 Build 之外，還有多個測試環境的 Image 也要 Build，這造成了我在這個專案上需要創建多個 Dockerfile\n發生了什麼問題? 我一開始的錯誤處理方式 菜鳥時期的我，以為 Dockerfile 就是一定得命名為\u0026quot;Dockerfile\u0026quot;，這導致了我沒辦法在專案根目錄下創建三個 Dockerfile，因為會導致命名衝突\n那我想出了什麼處理方式？相當簡單，很菜的我，一開始便自然地根據不同環境在專案下創建了不同的目錄，然後在目錄底下存放各自的 Dockerfile 就很類似這種感覺：\nE2Eproject/\r├── testenvironment1/\r│ └── Dockerfile\r├── testenvironment2/\r│ └── Dockerfile\r├── requirements.txt\r└── Dockerfile 接著便接著發生下一個問題 — 錯誤的建構上下文 以其中一個測試環境內的 Dockerfile 為範例，當時我的寫法如下，請特別注意 COPY ../../ /usr/src/app/ 這行\n# Use the official Python base image from the DockerHub. FROM python:3.12 # Set the working directory within the container. WORKDIR /usr/src/app # Set the PYTHONPATH environment variable. This is where Python looks for modules. # It\u0026#39;s set to the work directory to allow local modules to be found. ENV PYTHONPATH /usr/src/app # Copy the contents of the current host directory into the container\u0026#39;s work directory. COPY ../../ /usr/src/app/ # Install the project dependencies specified in the requirements.txt file. # The --no-cache-dir option is used to disable the cache and reduce the layer size. RUN pip install --no-cache-dir -r ../../requirements.txt # 略 ... RUN chmod +x /usr/src/app/start-tests.sh # The command to run the application. CMD [\u0026#34;sh\u0026#34;, \u0026#34;/usr/src/app/start-headless-tests.sh\u0026#34;] 會注意到，我使用了 ../../，會這麼寫是因為專案根目錄(或是說打包所需的檔案)都在此 Dockerfile 所處目錄的上面幾層 接著就是很自然的輸入下方指令，然後就出現 ERROR 了：\n$ cd testenvironment1 $ docker build -t e2e-project-testenv:v1 . Dockerfile:16 -------------------- 14 | # Install the project dependencies specified in the requirements.txt file. 15 | # The --no-cache-dir option is used to disable the cache and reduce the layer size. 16 | \u0026gt;\u0026gt;\u0026gt; RUN pip install --no-cache-dir -r ../../requirements.txt 17 | 18 | # Install additional dependencies for HTML report generation -------------------- ERROR: failed to solve: process \u0026#34;/bin/sh -c pip install --no-cache-dir -r ../../requirements.txt\u0026#34; did not complete successfully: exit code: 1 Service \u0026#39;E2E-project\u0026#39; failed to build : Build failed TL;DR Docker 建構上下文就是告訴 Docker 從哪個目錄開始打包檔案，例如：你在執行指令 docker built . 這個 \u0026ldquo;.\u0026rdquo; 就是建構上下文，Docker 會將這個目錄及其子目錄下的所有檔案作為建構上下文打包成 tar 檔案\nDockerfile 與 build image 的上下文目錄不必強關聯在一起\n我們在指令中指定一個目錄作為上下文，然後也透過 -f 參數指定使用哪個建構檔案，並且名稱可以自己任意命名\ndocker build -t e2e-project-testenv:v1 -f testenvironment1/Dockerfile /myapp 先來了解什麼是 Docker 建構上下文 推薦文章：深入理解 docker build 中的建構上下文\n什麼是 Docker 建構上下文(build context) 首先，讓我們簡單回顧一下 Docker 的基本概念。Docker 允許您打包應用程式和所需環境到一個稱為 \u0026ldquo;鏡像\u0026rdquo;(image) 的容器中。這個鏡像可以在任何安裝了 Docker 的系統上運行。\nDocker 建構上下文的概念：\n當您使用 docker build 命令建立 Docker 鏡像時，Docker 會將指定路徑下的檔案和目錄打包成一個 tar 檔案。 這個 tar 檔案被稱為 \u0026ldquo;建構上下文\u0026rdquo;(build context)。 為什麼需要建構上下文：\nDocker 的鏡像是在 Docker 伺服器（通常是遠端伺服器）上建構的。 為了建構鏡像，Docker 伺服器需要訪問到所有必要的檔案，比如原始碼、配置檔案等。 因此，客戶端（您的電腦）會把這些檔案打包成 tar 檔案，然後上傳給伺服器。 Dockerfile 和建構上下文：\nDockerfile 是一個包含了建構鏡像所需步驟的文本檔案。 在 Dockerfile 中，您可以引用建構上下文中的檔案。比如，您可以複製建構上下文中的檔案到鏡像裡，或者執行建構上下文中的腳本。 總結來說，Docker 建構上下文是 Docker 客戶端將建構鏡像所需的檔案打包並傳輸給 Docker 伺服器的過程。這確保了 Docker 伺服器有所有必要的檔案來建構鏡像。\n為何我一開始的處理方式會出現 ERROR? 關鍵就出在：\n當我們執行 docker build -t e2e-project-testenv:v1 .，Docker 客戶端會先將後面的指定路徑(.) 打包成一個 tar 檔案，傳送給 Docker 伺服器端，接著才會根據 Dockerfile 中所定義的腳本進行構建 什麼意思呢？\n我當時執行指令 cd testenvironment1 接著執行 docker build -t e2e-project-testenv:v1 . 事實上就是把 testenvironment1 這個目錄以及其子目錄下的所有檔案打包好，傳送至 Docker Daemon Docker 在 Build 的時候只能取用上下文的檔案，requirements.txt 位於這個目錄的上層(即 E2Eproject 目錄中)，因此它不會被包含在建構上下文中，也就無法在 Dockerfile 中被訪問。 更優雅的處理方式 如果建構鏡像時沒有明確指定 Dockerfile，那麼 Docker Client 默認在建構鏡像時指定的上下文路徑下找名字為 Dockerfile 的建構檔案\n但事實上，Dockerfile 與 build image 的上下文目錄不必強關聯在一起 我們在指令中指定一個目錄作為上下文 然後也透過 -f 參數指定使用哪個建構檔案 並且名稱可以自己任意命名！ 並且名稱可以自己任意命名！！ 並且名稱可以自己任意命名！！！ 這完完全全解惑了我當初菜鳥所以為的「 Dockerfile 就是一定得命名為\u0026quot;Dockerfile\u0026quot;」\n例如：\n$ cd E2Eproject $ docker build -t e2e-project-testenv:v1 -f testenvironment1/Dockerfile . 參考資料 Docker-学习系列25-Dockerfile-中的-COPY-与-ADD-命令.html\n深入理解 docker build 中的建構上下文\n","permalink":"https://shiun.me/blog/a-project-with-multiple-dockerfiles---an-introduction-to-build-context/","summary":"最近在寫 E2E 測試遇到一個問題，因 E2E 專案中，除了專案本身的 Docker Image 需要 Build 之外，還有多個測試環境的 Image 也要 Build，這造成了我在這個專案上需要創建多個 Dockerfile\n發生了什麼問題? 我一開始的錯誤處理方式 菜鳥時期的我，以為 Dockerfile 就是一定得命名為\u0026quot;Dockerfile\u0026quot;，這導致了我沒辦法在專案根目錄下創建三個 Dockerfile，因為會導致命名衝突\n那我想出了什麼處理方式？相當簡單，很菜的我，一開始便自然地根據不同環境在專案下創建了不同的目錄，然後在目錄底下存放各自的 Dockerfile 就很類似這種感覺：\nE2Eproject/\r├── testenvironment1/\r│ └── Dockerfile\r├── testenvironment2/\r│ └── Dockerfile\r├── requirements.txt\r└── Dockerfile 接著便接著發生下一個問題 — 錯誤的建構上下文 以其中一個測試環境內的 Dockerfile 為範例，當時我的寫法如下，請特別注意 COPY ../../ /usr/src/app/ 這行\n# Use the official Python base image from the DockerHub. FROM python:3.12 # Set the working directory within the container. WORKDIR /usr/src/app # Set the PYTHONPATH environment variable.","title":"一個專案需要多個 Dockerfile - 淺談建構上下文 (build context)"},{"content":"大家好我是 Shiun，這篇是我的個人網站的第一篇文章，會記錄我的動機以及現在的時空背景，以此來記錄一下自己的個人成長，未來回頭來看看自己成長多少\n架設網站的動機 動機與原因 會想要架設個人網站主要有以下原因：\n想要記錄自己的個人成長，以及隨手筆記 受到 Nic 的啟發 (Youtube連結)，覺得對於未來職涯的道路上會有所幫助，能夠建立個人品牌，彰顯專業 自己本身就很熱愛分享知識、技術，而且很享受上台演講的氛圍 看起來很帥 2024 年 1 月，下定決心 一直以來都想架一個自己的個人網站，但遲遲一直沒有下手，絕大部分是因為懶 XD，而我一直以來都會把自己的想法紀錄在 Google Keep 或是 Dropbox Paper\n直到 2024/01 下定決心今年的新希望(目標)一定要架好個人網站，開始寫文章，而且我今年(2024)也準備要畢業了，即將面對職場，這時候再不趕快產出有質量的內容就太虧了\n關於我 Hi 我是 Shiun，家裡有兩隻貓(娜娜 \u0026amp; 妮妮😺😺) 我目前就讀於某私立大學的資管系(2024 畢業)，同時也就職於：\nAWS Educate 5th Cloud Ambassador - Technical Support @AWS Backend Engineer Intern @eGroupAI 在 2024 年 3 月要接任：\nAWS Educate 6th Cloud Ambassador Team Lead (技術) @AWS Cloud Engineer Intern @eCloudValley 主要專精於後端與雲端及 DevOps 方面的技術：\nSpring boot Jenkins AWS Docker Selenium Pytest 除此之外，我也很擅長擔任領導者的角色，在求學職涯中，我幾乎都是擔任領導者的職位，像是在大學畢業專題中我也擔任了組長、PM、Product Owner、Backend Development，在畢業專題(作品連結)中上實踐了敏捷式開發(Scrum, Kanban)\n","permalink":"https://shiun.me/blog/my-first/","summary":"大家好我是 Shiun，這篇是我的個人網站的第一篇文章，會記錄我的動機以及現在的時空背景，以此來記錄一下自己的個人成長，未來回頭來看看自己成長多少\n架設網站的動機 動機與原因 會想要架設個人網站主要有以下原因：\n想要記錄自己的個人成長，以及隨手筆記 受到 Nic 的啟發 (Youtube連結)，覺得對於未來職涯的道路上會有所幫助，能夠建立個人品牌，彰顯專業 自己本身就很熱愛分享知識、技術，而且很享受上台演講的氛圍 看起來很帥 2024 年 1 月，下定決心 一直以來都想架一個自己的個人網站，但遲遲一直沒有下手，絕大部分是因為懶 XD，而我一直以來都會把自己的想法紀錄在 Google Keep 或是 Dropbox Paper\n直到 2024/01 下定決心今年的新希望(目標)一定要架好個人網站，開始寫文章，而且我今年(2024)也準備要畢業了，即將面對職場，這時候再不趕快產出有質量的內容就太虧了\n關於我 Hi 我是 Shiun，家裡有兩隻貓(娜娜 \u0026amp; 妮妮😺😺) 我目前就讀於某私立大學的資管系(2024 畢業)，同時也就職於：\nAWS Educate 5th Cloud Ambassador - Technical Support @AWS Backend Engineer Intern @eGroupAI 在 2024 年 3 月要接任：\nAWS Educate 6th Cloud Ambassador Team Lead (技術) @AWS Cloud Engineer Intern @eCloudValley 主要專精於後端與雲端及 DevOps 方面的技術：\nSpring boot Jenkins AWS Docker Selenium Pytest 除此之外，我也很擅長擔任領導者的角色，在求學職涯中，我幾乎都是擔任領導者的職位，像是在大學畢業專題中我也擔任了組長、PM、Product Owner、Backend Development，在畢業專題(作品連結)中上實踐了敏捷式開發(Scrum, Kanban)","title":"這個網站的第一篇文章 - 關於我 以及架站的動機"}]